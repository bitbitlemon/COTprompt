***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/NLPrompt/rn50.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.USE_OT', 'True', 'OPTIM.MAX_EPOCH', '50', 'TRAIN.CHECKPOINT_FREQ', '10']
output_dir: output/caltech101_nlprompt_16shot_seed1
resume: 
root: /NLPrompt-master/datasets/DATA
seed: 1
source_domains: None
target_domains: None
trainer: NLPrompt
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 0
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  BEGIN_RATE: 0.3
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  CURRICLUM_EPOCH: 0
  CURRICLUM_MODE: linear
  NAME: Caltech101
  NOISE_LABEL: True
  NOISE_RATE: 0.5
  NOISE_TYPE: sym
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PMODE: logP
  REG_E: 0.01
  REG_FEAT: 1.0
  REG_LAB: 1.0
  ROOT: /NLPrompt-master/datasets/DATA
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  USE_OT: True
  VAL_PERCENT: 0.1
  num_class: 100
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: RN50
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/caltech101_nlprompt_16shot_seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: NLPrompt
  NLPROMPT:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.5.1+cu124
Is debug build: False
CUDA used to build PyTorch: 12.4
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.3 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: version 3.22.1
Libc version: glibc-2.35

Python version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:27:36) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-83-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: 12.4.99
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 4090
Nvidia driver version: 560.35.05
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      43 bits physical, 48 bits virtual
Byte Order:                         Little Endian
CPU(s):                             128
On-line CPU(s) list:                0-127
Vendor ID:                          AuthenticAMD
Model name:                         AMD EPYC 7542 32-Core Processor
CPU family:                         23
Model:                              49
Thread(s) per core:                 2
Core(s) per socket:                 32
Socket(s):                          2
Stepping:                           0
Frequency boost:                    enabled
CPU max MHz:                        2900.0000
CPU min MHz:                        1500.0000
BogoMIPS:                           5800.45
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip rdpid overflow_recov succor smca sme sev sev_es
Virtualization:                     AMD-V
L1d cache:                          2 MiB (64 instances)
L1i cache:                          2 MiB (64 instances)
L2 cache:                           32 MiB (64 instances)
L3 cache:                           256 MiB (16 instances)
NUMA node(s):                       8
NUMA node0 CPU(s):                  0-7,64-71
NUMA node1 CPU(s):                  8-15,72-79
NUMA node2 CPU(s):                  16-23,80-87
NUMA node3 CPU(s):                  24-31,88-95
NUMA node4 CPU(s):                  32-39,96-103
NUMA node5 CPU(s):                  40-47,104-111
NUMA node6 CPU(s):                  48-55,112-119
NUMA node7 CPU(s):                  56-63,120-127
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        Not affected
Vulnerability L1tf:                 Not affected
Vulnerability Mds:                  Not affected
Vulnerability Meltdown:             Not affected
Vulnerability Mmio stale data:      Not affected
Vulnerability Retbleed:             Mitigation; untrained return thunk; SMT enabled with STIBP protection
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, STIBP always-on, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Not affected
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] flake8==7.0.0
[pip3] mypy==1.11.2
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.26.4
[pip3] numpydoc==1.7.0
[pip3] optree==0.14.0
[pip3] torch==2.5.1+cu124
[pip3] torchaudio==2.5.1+cu124
[pip3] torchvision==0.20.1+cu124
[pip3] triton==3.1.0
[conda] _anaconda_depends         2024.10             py312_mkl_0    defaults
[conda] blas                      1.0                         mkl    defaults
[conda] mkl                       2023.1.0         h213fc3f_46344    defaults
[conda] mkl-service               2.4.0           py312h5eee18b_1    defaults
[conda] mkl_fft                   1.3.10          py312h5eee18b_0    defaults
[conda] mkl_random                1.2.7           py312h526ad5a_0    defaults
[conda] numpy                     1.26.4          py312hc5e2394_0    defaults
[conda] numpy-base                1.26.4          py312h0da6c21_0    defaults
[conda] numpydoc                  1.7.0           py312h06a4308_0    defaults
[conda] optree                    0.14.0                   pypi_0    pypi
[conda] torch                     2.5.1+cu124              pypi_0    pypi
[conda] torchaudio                2.5.1+cu124              pypi_0    pypi
[conda] torchvision               0.20.1+cu124             pypi_0    pypi
[conda] triton                    3.1.0                    pypi_0    pypi
        Pillow (10.4.0)

Loading trainer: NLPrompt
Loading dataset: Caltech101
Reading split from /NLPrompt-master/datasets/DATA/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /NLPrompt-master/datasets/DATA/caltech-101/split_fewshot/shot_16-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
add noise 
Data loader size: 50
Data loader size: 4
Data loader size: 25
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      400
# test     2,465
---------  ----------
Loading CLIP (backbone: RN50)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/caltech101_nlprompt_16shot_seed1/tensorboard)
before epoch:data num: 1600
before epoch:different number: 868
confident_label rate tensor(0.2362, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 378
clean true:375
clean false:3
clean_rate:0.9920634920634921
noisy true:357
noisy false:865
after delete: len(clean_dataset) 378
after delete: len(noisy_dataset) 1222
epoch [1/50] batch [5/11] time 0.496 (0.415) data 0.457 (0.361) loss_x loss_x 2.4004 (2.7742) acc_x 78.1250 (65.6250) lr 1.0000e-05 eta 0:00:02
epoch [1/50] batch [10/11] time 0.393 (0.408) data 0.357 (0.362) loss_x loss_x 2.3730 (2.6076) acc_x 62.5000 (65.3125) lr 1.0000e-05 eta 0:00:00
epoch [1/50] batch [5/38] time 0.521 (0.423) data 0.403 (0.365) loss_u loss_u 0.9429 (0.9704) acc_u 15.6250 (10.6250) lr 1.0000e-05 eta 0:00:13
epoch [1/50] batch [10/38] time 0.397 (0.408) data 0.357 (0.352) loss_u loss_u 0.9629 (0.9644) acc_u 6.2500 (9.6875) lr 1.0000e-05 eta 0:00:11
epoch [1/50] batch [15/38] time 0.394 (0.403) data 0.354 (0.343) loss_u loss_u 0.9614 (0.9593) acc_u 9.3750 (11.2500) lr 1.0000e-05 eta 0:00:09
epoch [1/50] batch [20/38] time 0.411 (0.403) data 0.367 (0.346) loss_u loss_u 0.9453 (0.9595) acc_u 12.5000 (10.9375) lr 1.0000e-05 eta 0:00:07
epoch [1/50] batch [25/38] time 0.389 (0.402) data 0.270 (0.345) loss_u loss_u 0.9468 (0.9572) acc_u 15.6250 (11.0000) lr 1.0000e-05 eta 0:00:05
epoch [1/50] batch [30/38] time 0.313 (0.397) data 0.277 (0.343) loss_u loss_u 0.8882 (0.9514) acc_u 21.8750 (11.7708) lr 1.0000e-05 eta 0:00:03
epoch [1/50] batch [35/38] time 0.328 (0.395) data 0.287 (0.340) loss_u loss_u 0.9644 (0.9515) acc_u 9.3750 (11.4286) lr 1.0000e-05 eta 0:00:01
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 687
confident_label rate tensor(0.2956, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 473
clean true:467
clean false:6
clean_rate:0.9873150105708245
noisy true:446
noisy false:681
after delete: len(clean_dataset) 473
after delete: len(noisy_dataset) 1127
epoch [2/50] batch [5/14] time 0.472 (0.394) data 0.366 (0.341) loss_x loss_x 0.8638 (1.2135) acc_x 78.1250 (70.6250) lr 2.0000e-03 eta 0:00:03
epoch [2/50] batch [10/14] time 0.391 (0.387) data 0.284 (0.335) loss_x loss_x 0.9453 (0.9621) acc_x 75.0000 (76.2500) lr 2.0000e-03 eta 0:00:01
epoch [2/50] batch [5/35] time 0.312 (0.384) data 0.275 (0.339) loss_u loss_u 0.8589 (0.8962) acc_u 21.8750 (13.1250) lr 2.0000e-03 eta 0:00:11
epoch [2/50] batch [10/35] time 0.316 (0.379) data 0.280 (0.329) loss_u loss_u 0.9243 (0.8739) acc_u 6.2500 (15.3125) lr 2.0000e-03 eta 0:00:09
epoch [2/50] batch [15/35] time 0.394 (0.379) data 0.273 (0.328) loss_u loss_u 0.9268 (0.8715) acc_u 9.3750 (15.6250) lr 2.0000e-03 eta 0:00:07
epoch [2/50] batch [20/35] time 0.393 (0.376) data 0.357 (0.326) loss_u loss_u 0.8838 (0.8732) acc_u 15.6250 (15.4688) lr 2.0000e-03 eta 0:00:05
epoch [2/50] batch [25/35] time 0.393 (0.376) data 0.357 (0.326) loss_u loss_u 0.8159 (0.8745) acc_u 18.7500 (15.1250) lr 2.0000e-03 eta 0:00:03
epoch [2/50] batch [30/35] time 0.394 (0.377) data 0.358 (0.326) loss_u loss_u 0.8525 (0.8728) acc_u 18.7500 (15.8333) lr 2.0000e-03 eta 0:00:01
epoch [2/50] batch [35/35] time 0.394 (0.377) data 0.278 (0.326) loss_u loss_u 0.9282 (0.8708) acc_u 6.2500 (15.7143) lr 2.0000e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 507
confident_label rate tensor(0.3469, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 555
clean true:552
clean false:3
clean_rate:0.9945945945945946
noisy true:541
noisy false:504
after delete: len(clean_dataset) 555
after delete: len(noisy_dataset) 1045
epoch [3/50] batch [5/17] time 0.399 (0.361) data 0.363 (0.309) loss_x loss_x 1.0957 (1.0540) acc_x 71.8750 (70.6250) lr 1.9980e-03 eta 0:00:04
epoch [3/50] batch [10/17] time 0.401 (0.371) data 0.364 (0.320) loss_x loss_x 1.3740 (1.0012) acc_x 71.8750 (74.0625) lr 1.9980e-03 eta 0:00:02
epoch [3/50] batch [15/17] time 0.305 (0.374) data 0.265 (0.316) loss_x loss_x 0.3628 (0.9231) acc_x 84.3750 (75.6250) lr 1.9980e-03 eta 0:00:00
epoch [3/50] batch [5/32] time 0.311 (0.369) data 0.275 (0.310) loss_u loss_u 0.9209 (0.9165) acc_u 12.5000 (10.6250) lr 1.9980e-03 eta 0:00:09
epoch [3/50] batch [10/32] time 0.306 (0.371) data 0.270 (0.316) loss_u loss_u 0.9351 (0.9211) acc_u 9.3750 (10.0000) lr 1.9980e-03 eta 0:00:08
epoch [3/50] batch [15/32] time 0.392 (0.375) data 0.355 (0.323) loss_u loss_u 0.8970 (0.9241) acc_u 12.5000 (9.1667) lr 1.9980e-03 eta 0:00:06
epoch [3/50] batch [20/32] time 0.390 (0.373) data 0.274 (0.319) loss_u loss_u 0.8994 (0.9221) acc_u 12.5000 (9.3750) lr 1.9980e-03 eta 0:00:04
epoch [3/50] batch [25/32] time 0.310 (0.371) data 0.273 (0.318) loss_u loss_u 0.9253 (0.9114) acc_u 6.2500 (10.5000) lr 1.9980e-03 eta 0:00:02
epoch [3/50] batch [30/32] time 0.389 (0.372) data 0.277 (0.318) loss_u loss_u 0.9443 (0.9142) acc_u 3.1250 (9.8958) lr 1.9980e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 488
confident_label rate tensor(0.3456, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 553
clean true:551
clean false:2
clean_rate:0.9963833634719711
noisy true:561
noisy false:486
after delete: len(clean_dataset) 553
after delete: len(noisy_dataset) 1047
epoch [4/50] batch [5/17] time 0.385 (0.367) data 0.274 (0.300) loss_x loss_x 0.4336 (0.9986) acc_x 87.5000 (73.7500) lr 1.9921e-03 eta 0:00:04
epoch [4/50] batch [10/17] time 0.397 (0.366) data 0.358 (0.306) loss_x loss_x 0.5718 (0.7927) acc_x 81.2500 (79.6875) lr 1.9921e-03 eta 0:00:02
epoch [4/50] batch [15/17] time 0.325 (0.371) data 0.281 (0.313) loss_x loss_x 0.8013 (0.7590) acc_x 78.1250 (79.7917) lr 1.9921e-03 eta 0:00:00
epoch [4/50] batch [5/32] time 0.397 (0.375) data 0.360 (0.316) loss_u loss_u 0.8931 (0.8955) acc_u 9.3750 (10.6250) lr 1.9921e-03 eta 0:00:10
epoch [4/50] batch [10/32] time 0.395 (0.372) data 0.355 (0.311) loss_u loss_u 0.9023 (0.9007) acc_u 9.3750 (10.6250) lr 1.9921e-03 eta 0:00:08
epoch [4/50] batch [15/32] time 0.396 (0.373) data 0.284 (0.308) loss_u loss_u 0.9180 (0.9028) acc_u 9.3750 (11.0417) lr 1.9921e-03 eta 0:00:06
epoch [4/50] batch [20/32] time 0.397 (0.377) data 0.282 (0.311) loss_u loss_u 0.8652 (0.8981) acc_u 18.7500 (11.7188) lr 1.9921e-03 eta 0:00:04
epoch [4/50] batch [25/32] time 0.387 (0.375) data 0.351 (0.311) loss_u loss_u 0.8721 (0.8987) acc_u 12.5000 (11.5000) lr 1.9921e-03 eta 0:00:02
epoch [4/50] batch [30/32] time 0.390 (0.377) data 0.283 (0.315) loss_u loss_u 0.8989 (0.8976) acc_u 12.5000 (11.6667) lr 1.9921e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 472
confident_label rate tensor(0.3487, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 558
clean true:555
clean false:3
clean_rate:0.9946236559139785
noisy true:573
noisy false:469
after delete: len(clean_dataset) 558
after delete: len(noisy_dataset) 1042
epoch [5/50] batch [5/17] time 0.397 (0.375) data 0.361 (0.339) loss_x loss_x 0.9473 (0.8187) acc_x 75.0000 (76.2500) lr 1.9823e-03 eta 0:00:04
epoch [5/50] batch [10/17] time 0.306 (0.368) data 0.271 (0.324) loss_x loss_x 0.6982 (0.7391) acc_x 81.2500 (79.6875) lr 1.9823e-03 eta 0:00:02
epoch [5/50] batch [15/17] time 0.384 (0.371) data 0.278 (0.320) loss_x loss_x 0.6929 (0.7817) acc_x 78.1250 (79.5833) lr 1.9823e-03 eta 0:00:00
epoch [5/50] batch [5/32] time 0.308 (0.368) data 0.272 (0.311) loss_u loss_u 0.9307 (0.8988) acc_u 9.3750 (10.6250) lr 1.9823e-03 eta 0:00:09
epoch [5/50] batch [10/32] time 0.389 (0.369) data 0.277 (0.311) loss_u loss_u 0.9243 (0.9063) acc_u 9.3750 (10.3125) lr 1.9823e-03 eta 0:00:08
epoch [5/50] batch [15/32] time 0.310 (0.368) data 0.274 (0.311) loss_u loss_u 0.8823 (0.9021) acc_u 15.6250 (11.2500) lr 1.9823e-03 eta 0:00:06
epoch [5/50] batch [20/32] time 0.312 (0.367) data 0.276 (0.308) loss_u loss_u 0.9912 (0.9064) acc_u 0.0000 (10.6250) lr 1.9823e-03 eta 0:00:04
epoch [5/50] batch [25/32] time 0.412 (0.369) data 0.376 (0.311) loss_u loss_u 0.8965 (0.9061) acc_u 9.3750 (10.6250) lr 1.9823e-03 eta 0:00:02
epoch [5/50] batch [30/32] time 0.401 (0.372) data 0.364 (0.314) loss_u loss_u 0.8643 (0.9099) acc_u 15.6250 (10.3125) lr 1.9823e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 488
confident_label rate tensor(0.3556, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 569
clean true:566
clean false:3
clean_rate:0.9947275922671354
noisy true:546
noisy false:485
after delete: len(clean_dataset) 569
after delete: len(noisy_dataset) 1031
epoch [6/50] batch [5/17] time 0.308 (0.355) data 0.273 (0.287) loss_x loss_x 1.1855 (0.9550) acc_x 75.0000 (76.8750) lr 1.9686e-03 eta 0:00:04
epoch [6/50] batch [10/17] time 0.386 (0.376) data 0.280 (0.318) loss_x loss_x 0.9727 (0.8861) acc_x 75.0000 (77.1875) lr 1.9686e-03 eta 0:00:02
epoch [6/50] batch [15/17] time 0.306 (0.372) data 0.271 (0.321) loss_x loss_x 0.4983 (0.8039) acc_x 84.3750 (78.5417) lr 1.9686e-03 eta 0:00:00
epoch [6/50] batch [5/32] time 0.397 (0.372) data 0.361 (0.323) loss_u loss_u 0.8799 (0.9086) acc_u 12.5000 (10.6250) lr 1.9686e-03 eta 0:00:10
epoch [6/50] batch [10/32] time 0.395 (0.373) data 0.359 (0.323) loss_u loss_u 0.9268 (0.9097) acc_u 6.2500 (10.0000) lr 1.9686e-03 eta 0:00:08
epoch [6/50] batch [15/32] time 0.393 (0.371) data 0.358 (0.319) loss_u loss_u 0.9087 (0.8978) acc_u 9.3750 (11.4583) lr 1.9686e-03 eta 0:00:06
epoch [6/50] batch [20/32] time 0.320 (0.370) data 0.284 (0.316) loss_u loss_u 0.8154 (0.8945) acc_u 18.7500 (11.7188) lr 1.9686e-03 eta 0:00:04
epoch [6/50] batch [25/32] time 0.313 (0.368) data 0.276 (0.314) loss_u loss_u 0.9453 (0.8982) acc_u 3.1250 (11.1250) lr 1.9686e-03 eta 0:00:02
epoch [6/50] batch [30/32] time 0.311 (0.368) data 0.274 (0.312) loss_u loss_u 0.9399 (0.8993) acc_u 6.2500 (11.0417) lr 1.9686e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 453
confident_label rate tensor(0.3662, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 586
clean true:582
clean false:4
clean_rate:0.9931740614334471
noisy true:565
noisy false:449
after delete: len(clean_dataset) 586
after delete: len(noisy_dataset) 1014
epoch [7/50] batch [5/18] time 0.389 (0.356) data 0.353 (0.320) loss_x loss_x 1.2627 (0.6629) acc_x 71.8750 (83.7500) lr 1.9511e-03 eta 0:00:04
epoch [7/50] batch [10/18] time 0.395 (0.368) data 0.359 (0.332) loss_x loss_x 0.7915 (0.6859) acc_x 78.1250 (83.1250) lr 1.9511e-03 eta 0:00:02
epoch [7/50] batch [15/18] time 0.399 (0.379) data 0.364 (0.337) loss_x loss_x 0.5596 (0.6720) acc_x 84.3750 (83.1250) lr 1.9511e-03 eta 0:00:01
epoch [7/50] batch [5/31] time 0.391 (0.377) data 0.355 (0.334) loss_u loss_u 0.9521 (0.9120) acc_u 6.2500 (10.0000) lr 1.9511e-03 eta 0:00:09
epoch [7/50] batch [10/31] time 0.315 (0.374) data 0.278 (0.327) loss_u loss_u 0.9224 (0.9220) acc_u 6.2500 (8.4375) lr 1.9511e-03 eta 0:00:07
epoch [7/50] batch [15/31] time 0.311 (0.372) data 0.275 (0.326) loss_u loss_u 0.8716 (0.9275) acc_u 12.5000 (7.9167) lr 1.9511e-03 eta 0:00:05
epoch [7/50] batch [20/31] time 0.313 (0.371) data 0.277 (0.322) loss_u loss_u 0.8872 (0.9137) acc_u 12.5000 (9.2188) lr 1.9511e-03 eta 0:00:04
epoch [7/50] batch [25/31] time 0.311 (0.369) data 0.274 (0.320) loss_u loss_u 0.9312 (0.9132) acc_u 12.5000 (9.6250) lr 1.9511e-03 eta 0:00:02
epoch [7/50] batch [30/31] time 0.393 (0.370) data 0.277 (0.319) loss_u loss_u 0.9668 (0.9182) acc_u 6.2500 (9.1667) lr 1.9511e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 493
confident_label rate tensor(0.3531, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 565
clean true:560
clean false:5
clean_rate:0.9911504424778761
noisy true:547
noisy false:488
after delete: len(clean_dataset) 565
after delete: len(noisy_dataset) 1035
epoch [8/50] batch [5/17] time 0.396 (0.383) data 0.360 (0.347) loss_x loss_x 1.2949 (0.7562) acc_x 68.7500 (78.7500) lr 1.9298e-03 eta 0:00:04
epoch [8/50] batch [10/17] time 0.397 (0.381) data 0.362 (0.337) loss_x loss_x 0.8394 (0.7118) acc_x 81.2500 (80.6250) lr 1.9298e-03 eta 0:00:02
epoch [8/50] batch [15/17] time 0.397 (0.381) data 0.361 (0.334) loss_x loss_x 0.5728 (0.7203) acc_x 78.1250 (80.0000) lr 1.9298e-03 eta 0:00:00
epoch [8/50] batch [5/32] time 0.313 (0.374) data 0.278 (0.324) loss_u loss_u 0.9277 (0.9337) acc_u 9.3750 (7.5000) lr 1.9298e-03 eta 0:00:10
epoch [8/50] batch [10/32] time 0.394 (0.375) data 0.358 (0.324) loss_u loss_u 0.8423 (0.9016) acc_u 15.6250 (11.5625) lr 1.9298e-03 eta 0:00:08
epoch [8/50] batch [15/32] time 0.395 (0.378) data 0.358 (0.330) loss_u loss_u 0.8765 (0.8983) acc_u 15.6250 (11.6667) lr 1.9298e-03 eta 0:00:06
epoch [8/50] batch [20/32] time 0.385 (0.378) data 0.278 (0.325) loss_u loss_u 0.8716 (0.8967) acc_u 15.6250 (12.1875) lr 1.9298e-03 eta 0:00:04
epoch [8/50] batch [25/32] time 0.336 (0.377) data 0.297 (0.320) loss_u loss_u 0.9351 (0.8967) acc_u 6.2500 (11.8750) lr 1.9298e-03 eta 0:00:02
epoch [8/50] batch [30/32] time 0.395 (0.377) data 0.359 (0.321) loss_u loss_u 0.7803 (0.8934) acc_u 21.8750 (12.0833) lr 1.9298e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 476
confident_label rate tensor(0.3556, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 569
clean true:565
clean false:4
clean_rate:0.9929701230228472
noisy true:559
noisy false:472
after delete: len(clean_dataset) 569
after delete: len(noisy_dataset) 1031
epoch [9/50] batch [5/17] time 0.391 (0.354) data 0.355 (0.304) loss_x loss_x 0.6553 (0.6532) acc_x 87.5000 (82.5000) lr 1.9048e-03 eta 0:00:04
epoch [9/50] batch [10/17] time 0.395 (0.367) data 0.360 (0.324) loss_x loss_x 0.7168 (0.6748) acc_x 78.1250 (81.5625) lr 1.9048e-03 eta 0:00:02
epoch [9/50] batch [15/17] time 0.312 (0.365) data 0.277 (0.321) loss_x loss_x 0.4180 (0.6603) acc_x 84.3750 (81.8750) lr 1.9048e-03 eta 0:00:00
epoch [9/50] batch [5/32] time 0.402 (0.376) data 0.365 (0.329) loss_u loss_u 0.9502 (0.8633) acc_u 6.2500 (15.6250) lr 1.9048e-03 eta 0:00:10
epoch [9/50] batch [10/32] time 0.326 (0.381) data 0.290 (0.330) loss_u loss_u 0.9033 (0.8814) acc_u 15.6250 (13.1250) lr 1.9048e-03 eta 0:00:08
epoch [9/50] batch [15/32] time 0.384 (0.380) data 0.345 (0.330) loss_u loss_u 0.9048 (0.8939) acc_u 9.3750 (11.2500) lr 1.9048e-03 eta 0:00:06
epoch [9/50] batch [20/32] time 0.315 (0.378) data 0.276 (0.325) loss_u loss_u 0.9219 (0.9010) acc_u 9.3750 (10.6250) lr 1.9048e-03 eta 0:00:04
epoch [9/50] batch [25/32] time 0.387 (0.378) data 0.277 (0.325) loss_u loss_u 0.9058 (0.9016) acc_u 12.5000 (10.7500) lr 1.9048e-03 eta 0:00:02
epoch [9/50] batch [30/32] time 0.381 (0.376) data 0.275 (0.323) loss_u loss_u 0.8760 (0.9013) acc_u 12.5000 (10.8333) lr 1.9048e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 451
confident_label rate tensor(0.3762, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 602
clean true:597
clean false:5
clean_rate:0.9916943521594684
noisy true:552
noisy false:446
after delete: len(clean_dataset) 602
after delete: len(noisy_dataset) 998
epoch [10/50] batch [5/18] time 0.323 (0.358) data 0.287 (0.308) loss_x loss_x 0.9746 (0.7001) acc_x 71.8750 (81.2500) lr 1.8763e-03 eta 0:00:04
epoch [10/50] batch [10/18] time 0.398 (0.369) data 0.358 (0.325) loss_x loss_x 0.4519 (0.6857) acc_x 87.5000 (81.8750) lr 1.8763e-03 eta 0:00:02
epoch [10/50] batch [15/18] time 0.474 (0.378) data 0.365 (0.326) loss_x loss_x 0.3882 (0.6893) acc_x 90.6250 (81.8750) lr 1.8763e-03 eta 0:00:01
epoch [10/50] batch [5/31] time 0.392 (0.373) data 0.270 (0.319) loss_u loss_u 0.9980 (0.9313) acc_u 0.0000 (6.8750) lr 1.8763e-03 eta 0:00:09
epoch [10/50] batch [10/31] time 0.396 (0.374) data 0.280 (0.318) loss_u loss_u 0.8403 (0.9230) acc_u 15.6250 (7.5000) lr 1.8763e-03 eta 0:00:07
epoch [10/50] batch [15/31] time 0.320 (0.370) data 0.279 (0.311) loss_u loss_u 0.8994 (0.9205) acc_u 9.3750 (7.9167) lr 1.8763e-03 eta 0:00:05
epoch [10/50] batch [20/31] time 0.317 (0.371) data 0.278 (0.313) loss_u loss_u 0.8589 (0.9166) acc_u 15.6250 (8.9062) lr 1.8763e-03 eta 0:00:04
epoch [10/50] batch [25/31] time 0.396 (0.371) data 0.360 (0.315) loss_u loss_u 0.8789 (0.9120) acc_u 15.6250 (9.6250) lr 1.8763e-03 eta 0:00:02
epoch [10/50] batch [30/31] time 0.398 (0.373) data 0.357 (0.317) loss_u loss_u 0.8599 (0.9139) acc_u 12.5000 (9.3750) lr 1.8763e-03 eta 0:00:00
Checkpoint saved to output/caltech101_nlprompt_16shot_seed1/prompt_learner/model.pth.tar-10
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 446
confident_label rate tensor(0.3713, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 594
clean true:589
clean false:5
clean_rate:0.9915824915824916
noisy true:565
noisy false:441
after delete: len(clean_dataset) 594
after delete: len(noisy_dataset) 1006
epoch [11/50] batch [5/18] time 0.388 (0.352) data 0.277 (0.297) loss_x loss_x 0.8037 (0.9674) acc_x 78.1250 (76.2500) lr 1.8443e-03 eta 0:00:04
epoch [11/50] batch [10/18] time 0.396 (0.357) data 0.357 (0.302) loss_x loss_x 1.0166 (0.8709) acc_x 68.7500 (76.8750) lr 1.8443e-03 eta 0:00:02
epoch [11/50] batch [15/18] time 0.390 (0.371) data 0.351 (0.321) loss_x loss_x 1.0615 (0.8108) acc_x 75.0000 (79.3750) lr 1.8443e-03 eta 0:00:01
epoch [11/50] batch [5/31] time 0.311 (0.373) data 0.271 (0.320) loss_u loss_u 0.9966 (0.9159) acc_u 0.0000 (8.7500) lr 1.8443e-03 eta 0:00:09
epoch [11/50] batch [10/31] time 0.399 (0.374) data 0.359 (0.321) loss_u loss_u 0.8193 (0.9069) acc_u 21.8750 (10.6250) lr 1.8443e-03 eta 0:00:07
epoch [11/50] batch [15/31] time 0.400 (0.374) data 0.360 (0.321) loss_u loss_u 0.8276 (0.8983) acc_u 21.8750 (11.4583) lr 1.8443e-03 eta 0:00:05
epoch [11/50] batch [20/31] time 0.397 (0.373) data 0.357 (0.317) loss_u loss_u 0.9053 (0.8991) acc_u 9.3750 (11.4062) lr 1.8443e-03 eta 0:00:04
epoch [11/50] batch [25/31] time 0.386 (0.373) data 0.275 (0.316) loss_u loss_u 0.9375 (0.9064) acc_u 6.2500 (10.5000) lr 1.8443e-03 eta 0:00:02
epoch [11/50] batch [30/31] time 0.315 (0.372) data 0.275 (0.317) loss_u loss_u 0.9292 (0.9098) acc_u 6.2500 (10.1042) lr 1.8443e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 494
confident_label rate tensor(0.3544, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 567
clean true:566
clean false:1
clean_rate:0.9982363315696648
noisy true:540
noisy false:493
after delete: len(clean_dataset) 567
after delete: len(noisy_dataset) 1033
epoch [12/50] batch [5/17] time 0.401 (0.385) data 0.366 (0.349) loss_x loss_x 0.4275 (0.6509) acc_x 87.5000 (83.1250) lr 1.8090e-03 eta 0:00:04
epoch [12/50] batch [10/17] time 0.391 (0.382) data 0.276 (0.331) loss_x loss_x 0.6963 (0.6612) acc_x 81.2500 (81.8750) lr 1.8090e-03 eta 0:00:02
epoch [12/50] batch [15/17] time 0.401 (0.382) data 0.361 (0.335) loss_x loss_x 0.8013 (0.6720) acc_x 84.3750 (82.2917) lr 1.8090e-03 eta 0:00:00
epoch [12/50] batch [5/32] time 0.398 (0.378) data 0.357 (0.327) loss_u loss_u 0.9731 (0.9279) acc_u 3.1250 (6.8750) lr 1.8090e-03 eta 0:00:10
epoch [12/50] batch [10/32] time 0.395 (0.378) data 0.359 (0.329) loss_u loss_u 0.9185 (0.9156) acc_u 6.2500 (9.6875) lr 1.8090e-03 eta 0:00:08
epoch [12/50] batch [15/32] time 0.392 (0.379) data 0.355 (0.332) loss_u loss_u 0.9229 (0.9123) acc_u 12.5000 (10.4167) lr 1.8090e-03 eta 0:00:06
epoch [12/50] batch [20/32] time 0.399 (0.379) data 0.280 (0.329) loss_u loss_u 0.8501 (0.9010) acc_u 15.6250 (11.4062) lr 1.8090e-03 eta 0:00:04
epoch [12/50] batch [25/32] time 0.395 (0.377) data 0.359 (0.327) loss_u loss_u 0.8901 (0.8970) acc_u 12.5000 (11.7500) lr 1.8090e-03 eta 0:00:02
epoch [12/50] batch [30/32] time 0.401 (0.377) data 0.364 (0.327) loss_u loss_u 0.9180 (0.8994) acc_u 12.5000 (11.6667) lr 1.8090e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 450
confident_label rate tensor(0.3656, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 585
clean true:580
clean false:5
clean_rate:0.9914529914529915
noisy true:570
noisy false:445
after delete: len(clean_dataset) 585
after delete: len(noisy_dataset) 1015
epoch [13/50] batch [5/18] time 0.315 (0.371) data 0.276 (0.315) loss_x loss_x 0.4619 (0.5899) acc_x 90.6250 (85.6250) lr 1.7705e-03 eta 0:00:04
epoch [13/50] batch [10/18] time 0.389 (0.375) data 0.349 (0.327) loss_x loss_x 0.8174 (0.6759) acc_x 71.8750 (83.1250) lr 1.7705e-03 eta 0:00:02
epoch [13/50] batch [15/18] time 0.396 (0.377) data 0.356 (0.323) loss_x loss_x 0.3762 (0.6474) acc_x 90.6250 (84.5833) lr 1.7705e-03 eta 0:00:01
epoch [13/50] batch [5/31] time 0.399 (0.376) data 0.357 (0.323) loss_u loss_u 0.9067 (0.9062) acc_u 9.3750 (10.0000) lr 1.7705e-03 eta 0:00:09
epoch [13/50] batch [10/31] time 0.396 (0.376) data 0.284 (0.321) loss_u loss_u 0.9741 (0.9027) acc_u 3.1250 (10.9375) lr 1.7705e-03 eta 0:00:07
epoch [13/50] batch [15/31] time 0.395 (0.377) data 0.358 (0.321) loss_u loss_u 0.9141 (0.9071) acc_u 9.3750 (10.6250) lr 1.7705e-03 eta 0:00:06
epoch [13/50] batch [20/31] time 0.399 (0.378) data 0.359 (0.322) loss_u loss_u 0.9395 (0.9060) acc_u 6.2500 (10.3125) lr 1.7705e-03 eta 0:00:04
epoch [13/50] batch [25/31] time 0.395 (0.378) data 0.354 (0.322) loss_u loss_u 0.9590 (0.9098) acc_u 6.2500 (10.0000) lr 1.7705e-03 eta 0:00:02
epoch [13/50] batch [30/31] time 0.402 (0.376) data 0.362 (0.320) loss_u loss_u 0.9263 (0.9098) acc_u 6.2500 (9.8958) lr 1.7705e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 462
confident_label rate tensor(0.3688, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 590
clean true:586
clean false:4
clean_rate:0.9932203389830508
noisy true:552
noisy false:458
after delete: len(clean_dataset) 590
after delete: len(noisy_dataset) 1010
epoch [14/50] batch [5/18] time 0.397 (0.369) data 0.357 (0.315) loss_x loss_x 0.8193 (0.6316) acc_x 75.0000 (81.2500) lr 1.7290e-03 eta 0:00:04
epoch [14/50] batch [10/18] time 0.388 (0.373) data 0.349 (0.319) loss_x loss_x 1.0889 (0.6888) acc_x 78.1250 (81.5625) lr 1.7290e-03 eta 0:00:02
epoch [14/50] batch [15/18] time 0.318 (0.370) data 0.278 (0.315) loss_x loss_x 0.8228 (0.7186) acc_x 78.1250 (80.8333) lr 1.7290e-03 eta 0:00:01
epoch [14/50] batch [5/31] time 0.322 (0.372) data 0.277 (0.316) loss_u loss_u 0.9062 (0.9072) acc_u 9.3750 (10.6250) lr 1.7290e-03 eta 0:00:09
epoch [14/50] batch [10/31] time 0.395 (0.373) data 0.355 (0.317) loss_u loss_u 0.9609 (0.9114) acc_u 3.1250 (9.3750) lr 1.7290e-03 eta 0:00:07
epoch [14/50] batch [15/31] time 0.399 (0.374) data 0.360 (0.318) loss_u loss_u 0.8706 (0.9022) acc_u 12.5000 (10.4167) lr 1.7290e-03 eta 0:00:05
epoch [14/50] batch [20/31] time 0.373 (0.374) data 0.274 (0.319) loss_u loss_u 0.9663 (0.9031) acc_u 3.1250 (10.1562) lr 1.7290e-03 eta 0:00:04
epoch [14/50] batch [25/31] time 0.316 (0.373) data 0.276 (0.318) loss_u loss_u 0.9219 (0.9023) acc_u 9.3750 (10.5000) lr 1.7290e-03 eta 0:00:02
epoch [14/50] batch [30/31] time 0.401 (0.374) data 0.362 (0.318) loss_u loss_u 0.8608 (0.9004) acc_u 15.6250 (10.7292) lr 1.7290e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 425
confident_label rate tensor(0.3825, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 612
clean true:605
clean false:7
clean_rate:0.988562091503268
noisy true:570
noisy false:418
after delete: len(clean_dataset) 612
after delete: len(noisy_dataset) 988
epoch [15/50] batch [5/19] time 0.307 (0.371) data 0.268 (0.331) loss_x loss_x 0.7959 (0.7547) acc_x 84.3750 (83.7500) lr 1.6845e-03 eta 0:00:05
epoch [15/50] batch [10/19] time 0.317 (0.365) data 0.276 (0.318) loss_x loss_x 0.5967 (0.7467) acc_x 78.1250 (81.2500) lr 1.6845e-03 eta 0:00:03
epoch [15/50] batch [15/19] time 0.399 (0.377) data 0.363 (0.333) loss_x loss_x 0.3840 (0.7463) acc_x 81.2500 (80.8333) lr 1.6845e-03 eta 0:00:01
epoch [15/50] batch [5/30] time 0.366 (0.379) data 0.279 (0.324) loss_u loss_u 0.8525 (0.8616) acc_u 15.6250 (15.0000) lr 1.6845e-03 eta 0:00:09
epoch [15/50] batch [10/30] time 0.401 (0.377) data 0.365 (0.322) loss_u loss_u 0.8999 (0.8913) acc_u 12.5000 (12.1875) lr 1.6845e-03 eta 0:00:07
epoch [15/50] batch [15/30] time 0.397 (0.378) data 0.357 (0.323) loss_u loss_u 0.9243 (0.8947) acc_u 9.3750 (12.0833) lr 1.6845e-03 eta 0:00:05
epoch [15/50] batch [20/30] time 0.332 (0.376) data 0.292 (0.321) loss_u loss_u 0.9712 (0.9011) acc_u 3.1250 (11.4062) lr 1.6845e-03 eta 0:00:03
epoch [15/50] batch [25/30] time 0.309 (0.374) data 0.269 (0.317) loss_u loss_u 0.8975 (0.9068) acc_u 9.3750 (10.6250) lr 1.6845e-03 eta 0:00:01
epoch [15/50] batch [30/30] time 0.395 (0.374) data 0.355 (0.320) loss_u loss_u 0.9238 (0.9093) acc_u 6.2500 (10.2083) lr 1.6845e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 404
confident_label rate tensor(0.3887, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 622
clean true:615
clean false:7
clean_rate:0.9887459807073955
noisy true:581
noisy false:397
after delete: len(clean_dataset) 622
after delete: len(noisy_dataset) 978
epoch [16/50] batch [5/19] time 0.324 (0.359) data 0.286 (0.306) loss_x loss_x 0.6846 (0.9273) acc_x 81.2500 (77.5000) lr 1.6374e-03 eta 0:00:05
epoch [16/50] batch [10/19] time 0.396 (0.369) data 0.356 (0.323) loss_x loss_x 0.4326 (0.8235) acc_x 81.2500 (79.3750) lr 1.6374e-03 eta 0:00:03
epoch [16/50] batch [15/19] time 0.371 (0.377) data 0.277 (0.324) loss_x loss_x 0.5732 (0.7366) acc_x 84.3750 (81.0417) lr 1.6374e-03 eta 0:00:01
epoch [16/50] batch [5/30] time 0.406 (0.379) data 0.364 (0.324) loss_u loss_u 0.8599 (0.9248) acc_u 12.5000 (7.5000) lr 1.6374e-03 eta 0:00:09
epoch [16/50] batch [10/30] time 0.393 (0.382) data 0.354 (0.330) loss_u loss_u 0.9355 (0.9274) acc_u 12.5000 (8.1250) lr 1.6374e-03 eta 0:00:07
epoch [16/50] batch [15/30] time 0.404 (0.385) data 0.363 (0.334) loss_u loss_u 0.9341 (0.9220) acc_u 9.3750 (9.1667) lr 1.6374e-03 eta 0:00:05
epoch [16/50] batch [20/30] time 0.309 (0.384) data 0.273 (0.333) loss_u loss_u 0.9546 (0.9268) acc_u 6.2500 (8.4375) lr 1.6374e-03 eta 0:00:03
epoch [16/50] batch [25/30] time 0.489 (0.388) data 0.378 (0.335) loss_u loss_u 0.9639 (0.9259) acc_u 3.1250 (8.5000) lr 1.6374e-03 eta 0:00:01
epoch [16/50] batch [30/30] time 0.324 (0.385) data 0.288 (0.332) loss_u loss_u 0.9854 (0.9257) acc_u 0.0000 (8.7500) lr 1.6374e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 440
confident_label rate tensor(0.3831, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 613
clean true:608
clean false:5
clean_rate:0.9918433931484503
noisy true:552
noisy false:435
after delete: len(clean_dataset) 613
after delete: len(noisy_dataset) 987
epoch [17/50] batch [5/19] time 0.395 (0.352) data 0.355 (0.311) loss_x loss_x 1.0605 (0.8616) acc_x 71.8750 (78.7500) lr 1.5878e-03 eta 0:00:04
epoch [17/50] batch [10/19] time 0.315 (0.365) data 0.274 (0.318) loss_x loss_x 0.5347 (0.8186) acc_x 84.3750 (81.2500) lr 1.5878e-03 eta 0:00:03
epoch [17/50] batch [15/19] time 0.402 (0.370) data 0.362 (0.315) loss_x loss_x 0.7178 (0.7560) acc_x 78.1250 (82.0833) lr 1.5878e-03 eta 0:00:01
epoch [17/50] batch [5/30] time 0.308 (0.373) data 0.272 (0.319) loss_u loss_u 0.8555 (0.9172) acc_u 12.5000 (8.7500) lr 1.5878e-03 eta 0:00:09
epoch [17/50] batch [10/30] time 0.399 (0.374) data 0.363 (0.320) loss_u loss_u 0.9229 (0.9104) acc_u 6.2500 (9.0625) lr 1.5878e-03 eta 0:00:07
epoch [17/50] batch [15/30] time 0.331 (0.372) data 0.294 (0.314) loss_u loss_u 0.8618 (0.9074) acc_u 18.7500 (10.2083) lr 1.5878e-03 eta 0:00:05
epoch [17/50] batch [20/30] time 0.398 (0.373) data 0.362 (0.318) loss_u loss_u 0.7817 (0.9033) acc_u 25.0000 (10.9375) lr 1.5878e-03 eta 0:00:03
epoch [17/50] batch [25/30] time 0.398 (0.374) data 0.362 (0.320) loss_u loss_u 0.9209 (0.9050) acc_u 9.3750 (11.0000) lr 1.5878e-03 eta 0:00:01
epoch [17/50] batch [30/30] time 0.388 (0.376) data 0.278 (0.321) loss_u loss_u 0.9790 (0.9139) acc_u 0.0000 (9.7917) lr 1.5878e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 436
confident_label rate tensor(0.3713, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 594
clean true:592
clean false:2
clean_rate:0.9966329966329966
noisy true:572
noisy false:434
after delete: len(clean_dataset) 594
after delete: len(noisy_dataset) 1006
epoch [18/50] batch [5/18] time 0.392 (0.402) data 0.281 (0.331) loss_x loss_x 0.8301 (0.6629) acc_x 75.0000 (82.5000) lr 1.5358e-03 eta 0:00:05
epoch [18/50] batch [10/18] time 0.395 (0.412) data 0.277 (0.341) loss_x loss_x 0.5845 (0.6301) acc_x 84.3750 (82.5000) lr 1.5358e-03 eta 0:00:03
epoch [18/50] batch [15/18] time 0.400 (0.402) data 0.359 (0.341) loss_x loss_x 0.9102 (0.6259) acc_x 71.8750 (81.6667) lr 1.5358e-03 eta 0:00:01
epoch [18/50] batch [5/31] time 0.408 (0.401) data 0.368 (0.328) loss_u loss_u 0.9746 (0.9315) acc_u 0.0000 (6.8750) lr 1.5358e-03 eta 0:00:10
epoch [18/50] batch [10/31] time 0.312 (0.397) data 0.273 (0.325) loss_u loss_u 0.8545 (0.9305) acc_u 15.6250 (7.5000) lr 1.5358e-03 eta 0:00:08
epoch [18/50] batch [15/31] time 0.314 (0.392) data 0.273 (0.322) loss_u loss_u 0.7886 (0.9165) acc_u 25.0000 (9.3750) lr 1.5358e-03 eta 0:00:06
epoch [18/50] batch [20/31] time 0.401 (0.390) data 0.360 (0.323) loss_u loss_u 0.8804 (0.9106) acc_u 12.5000 (10.0000) lr 1.5358e-03 eta 0:00:04
epoch [18/50] batch [25/31] time 0.383 (0.386) data 0.272 (0.320) loss_u loss_u 0.9771 (0.9113) acc_u 3.1250 (9.8750) lr 1.5358e-03 eta 0:00:02
epoch [18/50] batch [30/31] time 0.394 (0.386) data 0.355 (0.321) loss_u loss_u 0.8066 (0.9024) acc_u 21.8750 (10.9375) lr 1.5358e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 424
confident_label rate tensor(0.3744, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 599
clean true:594
clean false:5
clean_rate:0.991652754590985
noisy true:582
noisy false:419
after delete: len(clean_dataset) 599
after delete: len(noisy_dataset) 1001
epoch [19/50] batch [5/18] time 0.413 (0.397) data 0.377 (0.332) loss_x loss_x 0.5957 (0.5636) acc_x 78.1250 (80.6250) lr 1.4818e-03 eta 0:00:05
epoch [19/50] batch [10/18] time 0.413 (0.399) data 0.376 (0.334) loss_x loss_x 0.7920 (0.6610) acc_x 78.1250 (79.6875) lr 1.4818e-03 eta 0:00:03
epoch [19/50] batch [15/18] time 0.400 (0.399) data 0.280 (0.333) loss_x loss_x 0.6851 (0.5889) acc_x 84.3750 (82.2917) lr 1.4818e-03 eta 0:00:01
epoch [19/50] batch [5/31] time 0.394 (0.395) data 0.278 (0.325) loss_u loss_u 0.9585 (0.9052) acc_u 6.2500 (10.0000) lr 1.4818e-03 eta 0:00:10
epoch [19/50] batch [10/31] time 0.315 (0.389) data 0.274 (0.322) loss_u loss_u 0.8813 (0.8985) acc_u 15.6250 (11.2500) lr 1.4818e-03 eta 0:00:08
epoch [19/50] batch [15/31] time 0.400 (0.391) data 0.360 (0.325) loss_u loss_u 0.9404 (0.9080) acc_u 6.2500 (9.7917) lr 1.4818e-03 eta 0:00:06
epoch [19/50] batch [20/31] time 0.475 (0.394) data 0.364 (0.330) loss_u loss_u 0.8892 (0.9071) acc_u 12.5000 (10.3125) lr 1.4818e-03 eta 0:00:04
epoch [19/50] batch [25/31] time 0.389 (0.392) data 0.277 (0.329) loss_u loss_u 0.8955 (0.9071) acc_u 12.5000 (10.3750) lr 1.4818e-03 eta 0:00:02
epoch [19/50] batch [30/31] time 0.405 (0.393) data 0.363 (0.331) loss_u loss_u 0.8643 (0.9089) acc_u 12.5000 (9.8958) lr 1.4818e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 440
confident_label rate tensor(0.3719, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 595
clean true:590
clean false:5
clean_rate:0.9915966386554622
noisy true:570
noisy false:435
after delete: len(clean_dataset) 595
after delete: len(noisy_dataset) 1005
epoch [20/50] batch [5/18] time 0.312 (0.363) data 0.272 (0.323) loss_x loss_x 0.8042 (0.7364) acc_x 78.1250 (80.0000) lr 1.4258e-03 eta 0:00:04
epoch [20/50] batch [10/18] time 0.395 (0.380) data 0.277 (0.332) loss_x loss_x 0.5146 (0.6814) acc_x 87.5000 (80.0000) lr 1.4258e-03 eta 0:00:03
epoch [20/50] batch [15/18] time 0.389 (0.380) data 0.278 (0.330) loss_x loss_x 0.9009 (0.6638) acc_x 68.7500 (80.2083) lr 1.4258e-03 eta 0:00:01
epoch [20/50] batch [5/31] time 0.396 (0.374) data 0.277 (0.321) loss_u loss_u 0.8550 (0.8457) acc_u 18.7500 (18.1250) lr 1.4258e-03 eta 0:00:09
epoch [20/50] batch [10/31] time 0.380 (0.368) data 0.340 (0.317) loss_u loss_u 0.8691 (0.8799) acc_u 15.6250 (14.0625) lr 1.4258e-03 eta 0:00:07
epoch [20/50] batch [15/31] time 0.310 (0.367) data 0.270 (0.318) loss_u loss_u 0.8276 (0.8834) acc_u 18.7500 (13.5417) lr 1.4258e-03 eta 0:00:05
epoch [20/50] batch [20/31] time 0.393 (0.366) data 0.354 (0.316) loss_u loss_u 0.8823 (0.8881) acc_u 15.6250 (13.1250) lr 1.4258e-03 eta 0:00:04
epoch [20/50] batch [25/31] time 0.396 (0.365) data 0.356 (0.313) loss_u loss_u 0.8921 (0.8875) acc_u 9.3750 (13.0000) lr 1.4258e-03 eta 0:00:02
epoch [20/50] batch [30/31] time 0.399 (0.367) data 0.359 (0.316) loss_u loss_u 0.8462 (0.8842) acc_u 21.8750 (13.5417) lr 1.4258e-03 eta 0:00:00
Checkpoint saved to output/caltech101_nlprompt_16shot_seed1/prompt_learner/model.pth.tar-20
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 408
confident_label rate tensor(0.3794, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 607
clean true:603
clean false:4
clean_rate:0.9934102141680395
noisy true:589
noisy false:404
after delete: len(clean_dataset) 607
after delete: len(noisy_dataset) 993
epoch [21/50] batch [5/18] time 0.400 (0.355) data 0.361 (0.300) loss_x loss_x 0.6572 (0.7510) acc_x 84.3750 (81.2500) lr 1.3681e-03 eta 0:00:04
epoch [21/50] batch [10/18] time 0.311 (0.357) data 0.272 (0.295) loss_x loss_x 0.8398 (0.6646) acc_x 84.3750 (82.8125) lr 1.3681e-03 eta 0:00:02
epoch [21/50] batch [15/18] time 0.396 (0.365) data 0.356 (0.301) loss_x loss_x 0.6245 (0.7420) acc_x 90.6250 (82.9167) lr 1.3681e-03 eta 0:00:01
epoch [21/50] batch [5/31] time 0.395 (0.372) data 0.277 (0.307) loss_u loss_u 0.9795 (0.9005) acc_u 0.0000 (11.2500) lr 1.3681e-03 eta 0:00:09
epoch [21/50] batch [10/31] time 0.390 (0.370) data 0.269 (0.306) loss_u loss_u 0.9238 (0.9062) acc_u 9.3750 (10.6250) lr 1.3681e-03 eta 0:00:07
epoch [21/50] batch [15/31] time 0.403 (0.369) data 0.364 (0.309) loss_u loss_u 0.8652 (0.8977) acc_u 15.6250 (11.6667) lr 1.3681e-03 eta 0:00:05
epoch [21/50] batch [20/31] time 0.318 (0.368) data 0.280 (0.308) loss_u loss_u 0.8765 (0.8998) acc_u 15.6250 (11.4062) lr 1.3681e-03 eta 0:00:04
epoch [21/50] batch [25/31] time 0.319 (0.369) data 0.273 (0.312) loss_u loss_u 0.9570 (0.8981) acc_u 3.1250 (11.3750) lr 1.3681e-03 eta 0:00:02
epoch [21/50] batch [30/31] time 0.394 (0.370) data 0.354 (0.314) loss_u loss_u 0.9277 (0.9030) acc_u 9.3750 (10.9375) lr 1.3681e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 423
confident_label rate tensor(0.3812, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 610
clean true:604
clean false:6
clean_rate:0.9901639344262295
noisy true:573
noisy false:417
after delete: len(clean_dataset) 610
after delete: len(noisy_dataset) 990
epoch [22/50] batch [5/19] time 0.391 (0.336) data 0.350 (0.281) loss_x loss_x 0.7578 (0.6319) acc_x 84.3750 (84.3750) lr 1.3090e-03 eta 0:00:04
epoch [22/50] batch [10/19] time 0.392 (0.348) data 0.354 (0.285) loss_x loss_x 0.0707 (0.5731) acc_x 100.0000 (85.3125) lr 1.3090e-03 eta 0:00:03
epoch [22/50] batch [15/19] time 0.470 (0.357) data 0.366 (0.293) loss_x loss_x 1.2158 (0.6226) acc_x 78.1250 (84.1667) lr 1.3090e-03 eta 0:00:01
epoch [22/50] batch [5/30] time 0.403 (0.362) data 0.362 (0.301) loss_u loss_u 0.9141 (0.9205) acc_u 9.3750 (8.7500) lr 1.3090e-03 eta 0:00:09
epoch [22/50] batch [10/30] time 0.306 (0.362) data 0.268 (0.302) loss_u loss_u 0.8965 (0.9113) acc_u 12.5000 (10.3125) lr 1.3090e-03 eta 0:00:07
epoch [22/50] batch [15/30] time 0.315 (0.361) data 0.276 (0.303) loss_u loss_u 0.9082 (0.9082) acc_u 12.5000 (10.8333) lr 1.3090e-03 eta 0:00:05
epoch [22/50] batch [20/30] time 0.401 (0.364) data 0.362 (0.306) loss_u loss_u 0.8916 (0.9126) acc_u 12.5000 (10.0000) lr 1.3090e-03 eta 0:00:03
epoch [22/50] batch [25/30] time 0.309 (0.363) data 0.270 (0.306) loss_u loss_u 0.9443 (0.9164) acc_u 6.2500 (9.7500) lr 1.3090e-03 eta 0:00:01
epoch [22/50] batch [30/30] time 0.394 (0.367) data 0.354 (0.310) loss_u loss_u 0.8804 (0.9181) acc_u 12.5000 (9.4792) lr 1.3090e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 410
confident_label rate tensor(0.3825, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 612
clean true:608
clean false:4
clean_rate:0.9934640522875817
noisy true:582
noisy false:406
after delete: len(clean_dataset) 612
after delete: len(noisy_dataset) 988
epoch [23/50] batch [5/19] time 0.380 (0.380) data 0.268 (0.297) loss_x loss_x 0.5400 (0.5161) acc_x 87.5000 (86.8750) lr 1.2487e-03 eta 0:00:05
epoch [23/50] batch [10/19] time 0.392 (0.371) data 0.353 (0.304) loss_x loss_x 0.3030 (0.6206) acc_x 90.6250 (83.7500) lr 1.2487e-03 eta 0:00:03
epoch [23/50] batch [15/19] time 0.322 (0.368) data 0.283 (0.305) loss_x loss_x 0.2393 (0.6061) acc_x 96.8750 (84.3750) lr 1.2487e-03 eta 0:00:01
epoch [23/50] batch [5/30] time 0.381 (0.375) data 0.270 (0.311) loss_u loss_u 0.9077 (0.9233) acc_u 9.3750 (8.7500) lr 1.2487e-03 eta 0:00:09
epoch [23/50] batch [10/30] time 0.400 (0.373) data 0.361 (0.311) loss_u loss_u 0.9121 (0.9031) acc_u 9.3750 (11.2500) lr 1.2487e-03 eta 0:00:07
epoch [23/50] batch [15/30] time 0.308 (0.371) data 0.268 (0.305) loss_u loss_u 0.8774 (0.9018) acc_u 12.5000 (11.6667) lr 1.2487e-03 eta 0:00:05
epoch [23/50] batch [20/30] time 0.395 (0.372) data 0.356 (0.308) loss_u loss_u 0.9990 (0.9093) acc_u 0.0000 (10.7812) lr 1.2487e-03 eta 0:00:03
epoch [23/50] batch [25/30] time 0.397 (0.373) data 0.277 (0.308) loss_u loss_u 0.8979 (0.9084) acc_u 12.5000 (10.6250) lr 1.2487e-03 eta 0:00:01
epoch [23/50] batch [30/30] time 0.402 (0.372) data 0.362 (0.308) loss_u loss_u 0.9351 (0.9047) acc_u 6.2500 (11.1458) lr 1.2487e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 447
confident_label rate tensor(0.3806, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 609
clean true:606
clean false:3
clean_rate:0.9950738916256158
noisy true:547
noisy false:444
after delete: len(clean_dataset) 609
after delete: len(noisy_dataset) 991
epoch [24/50] batch [5/19] time 0.401 (0.392) data 0.361 (0.352) loss_x loss_x 0.6836 (0.6125) acc_x 81.2500 (82.5000) lr 1.1874e-03 eta 0:00:05
epoch [24/50] batch [10/19] time 0.316 (0.395) data 0.278 (0.342) loss_x loss_x 0.3594 (0.5596) acc_x 93.7500 (85.0000) lr 1.1874e-03 eta 0:00:03
epoch [24/50] batch [15/19] time 0.312 (0.391) data 0.273 (0.342) loss_x loss_x 0.4641 (0.6424) acc_x 81.2500 (82.5000) lr 1.1874e-03 eta 0:00:01
epoch [24/50] batch [5/30] time 0.393 (0.385) data 0.355 (0.337) loss_u loss_u 0.8745 (0.9204) acc_u 15.6250 (9.3750) lr 1.1874e-03 eta 0:00:09
epoch [24/50] batch [10/30] time 0.319 (0.385) data 0.279 (0.333) loss_u loss_u 0.9272 (0.9253) acc_u 9.3750 (8.4375) lr 1.1874e-03 eta 0:00:07
epoch [24/50] batch [15/30] time 0.393 (0.384) data 0.354 (0.331) loss_u loss_u 0.9370 (0.9206) acc_u 6.2500 (8.9583) lr 1.1874e-03 eta 0:00:05
epoch [24/50] batch [20/30] time 0.390 (0.383) data 0.271 (0.328) loss_u loss_u 0.9170 (0.9171) acc_u 9.3750 (8.9062) lr 1.1874e-03 eta 0:00:03
epoch [24/50] batch [25/30] time 0.392 (0.383) data 0.352 (0.330) loss_u loss_u 0.9194 (0.9140) acc_u 6.2500 (9.0000) lr 1.1874e-03 eta 0:00:01
epoch [24/50] batch [30/30] time 0.380 (0.382) data 0.274 (0.326) loss_u loss_u 0.9590 (0.9079) acc_u 9.3750 (9.7917) lr 1.1874e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 440
confident_label rate tensor(0.3762, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 602
clean true:597
clean false:5
clean_rate:0.9916943521594684
noisy true:563
noisy false:435
after delete: len(clean_dataset) 602
after delete: len(noisy_dataset) 998
epoch [25/50] batch [5/18] time 0.310 (0.352) data 0.270 (0.283) loss_x loss_x 0.2218 (0.5774) acc_x 90.6250 (85.0000) lr 1.1253e-03 eta 0:00:04
epoch [25/50] batch [10/18] time 0.391 (0.365) data 0.273 (0.295) loss_x loss_x 0.4885 (0.6963) acc_x 81.2500 (82.1875) lr 1.1253e-03 eta 0:00:02
epoch [25/50] batch [15/18] time 0.391 (0.364) data 0.356 (0.300) loss_x loss_x 0.8545 (0.6617) acc_x 78.1250 (82.2917) lr 1.1253e-03 eta 0:00:01
epoch [25/50] batch [5/31] time 0.395 (0.367) data 0.274 (0.306) loss_u loss_u 0.8975 (0.8670) acc_u 12.5000 (15.6250) lr 1.1253e-03 eta 0:00:09
epoch [25/50] batch [10/31] time 0.396 (0.366) data 0.360 (0.307) loss_u loss_u 0.8833 (0.8951) acc_u 15.6250 (12.5000) lr 1.1253e-03 eta 0:00:07
epoch [25/50] batch [15/31] time 0.394 (0.368) data 0.275 (0.307) loss_u loss_u 0.8174 (0.8869) acc_u 21.8750 (13.3333) lr 1.1253e-03 eta 0:00:05
epoch [25/50] batch [20/31] time 0.314 (0.367) data 0.278 (0.308) loss_u loss_u 0.9204 (0.8980) acc_u 6.2500 (11.8750) lr 1.1253e-03 eta 0:00:04
epoch [25/50] batch [25/31] time 0.393 (0.368) data 0.279 (0.310) loss_u loss_u 0.9155 (0.8976) acc_u 9.3750 (11.8750) lr 1.1253e-03 eta 0:00:02
epoch [25/50] batch [30/31] time 0.404 (0.370) data 0.368 (0.312) loss_u loss_u 0.9390 (0.8948) acc_u 6.2500 (12.0833) lr 1.1253e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 408
confident_label rate tensor(0.3800, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 608
clean true:604
clean false:4
clean_rate:0.993421052631579
noisy true:588
noisy false:404
after delete: len(clean_dataset) 608
after delete: len(noisy_dataset) 992
epoch [26/50] batch [5/19] time 0.322 (0.358) data 0.286 (0.307) loss_x loss_x 0.8916 (0.7476) acc_x 78.1250 (81.8750) lr 1.0628e-03 eta 0:00:05
epoch [26/50] batch [10/19] time 0.319 (0.369) data 0.280 (0.317) loss_x loss_x 0.8228 (0.7491) acc_x 81.2500 (81.2500) lr 1.0628e-03 eta 0:00:03
epoch [26/50] batch [15/19] time 0.398 (0.379) data 0.362 (0.326) loss_x loss_x 0.4514 (0.7094) acc_x 87.5000 (82.2917) lr 1.0628e-03 eta 0:00:01
epoch [26/50] batch [5/31] time 0.381 (0.378) data 0.271 (0.321) loss_u loss_u 0.9189 (0.8708) acc_u 9.3750 (14.3750) lr 1.0628e-03 eta 0:00:09
epoch [26/50] batch [10/31] time 0.386 (0.375) data 0.276 (0.318) loss_u loss_u 0.9629 (0.8856) acc_u 3.1250 (12.5000) lr 1.0628e-03 eta 0:00:07
epoch [26/50] batch [15/31] time 0.391 (0.373) data 0.271 (0.314) loss_u loss_u 0.9209 (0.8975) acc_u 6.2500 (10.8333) lr 1.0628e-03 eta 0:00:05
epoch [26/50] batch [20/31] time 0.401 (0.371) data 0.361 (0.313) loss_u loss_u 0.9375 (0.9021) acc_u 6.2500 (10.3125) lr 1.0628e-03 eta 0:00:04
epoch [26/50] batch [25/31] time 0.395 (0.372) data 0.356 (0.315) loss_u loss_u 0.8882 (0.9004) acc_u 12.5000 (10.5000) lr 1.0628e-03 eta 0:00:02
epoch [26/50] batch [30/31] time 0.321 (0.371) data 0.282 (0.313) loss_u loss_u 0.9824 (0.9063) acc_u 3.1250 (10.1042) lr 1.0628e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 411
confident_label rate tensor(0.3869, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 619
clean true:612
clean false:7
clean_rate:0.9886914378029079
noisy true:577
noisy false:404
after delete: len(clean_dataset) 619
after delete: len(noisy_dataset) 981
epoch [27/50] batch [5/19] time 0.302 (0.354) data 0.266 (0.314) loss_x loss_x 0.3608 (0.7129) acc_x 81.2500 (80.6250) lr 1.0000e-03 eta 0:00:04
epoch [27/50] batch [10/19] time 0.402 (0.376) data 0.366 (0.339) loss_x loss_x 0.6353 (0.6852) acc_x 87.5000 (82.8125) lr 1.0000e-03 eta 0:00:03
epoch [27/50] batch [15/19] time 0.395 (0.378) data 0.360 (0.336) loss_x loss_x 0.4607 (0.6799) acc_x 87.5000 (82.2917) lr 1.0000e-03 eta 0:00:01
epoch [27/50] batch [5/30] time 0.398 (0.378) data 0.362 (0.335) loss_u loss_u 0.8589 (0.9152) acc_u 15.6250 (10.0000) lr 1.0000e-03 eta 0:00:09
epoch [27/50] batch [10/30] time 0.400 (0.378) data 0.365 (0.334) loss_u loss_u 0.9448 (0.8967) acc_u 6.2500 (11.2500) lr 1.0000e-03 eta 0:00:07
epoch [27/50] batch [15/30] time 0.314 (0.376) data 0.278 (0.330) loss_u loss_u 0.8950 (0.8983) acc_u 12.5000 (10.8333) lr 1.0000e-03 eta 0:00:05
epoch [27/50] batch [20/30] time 0.318 (0.373) data 0.283 (0.325) loss_u loss_u 0.9644 (0.9060) acc_u 6.2500 (10.6250) lr 1.0000e-03 eta 0:00:03
epoch [27/50] batch [25/30] time 0.393 (0.376) data 0.279 (0.328) loss_u loss_u 0.8711 (0.9066) acc_u 12.5000 (10.7500) lr 1.0000e-03 eta 0:00:01
epoch [27/50] batch [30/30] time 0.396 (0.375) data 0.360 (0.325) loss_u loss_u 0.8862 (0.9059) acc_u 12.5000 (10.5208) lr 1.0000e-03 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 438
confident_label rate tensor(0.3762, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 602
clean true:601
clean false:1
clean_rate:0.9983388704318937
noisy true:561
noisy false:437
after delete: len(clean_dataset) 602
after delete: len(noisy_dataset) 998
epoch [28/50] batch [5/18] time 0.310 (0.357) data 0.274 (0.304) loss_x loss_x 0.8125 (0.6295) acc_x 81.2500 (83.7500) lr 9.3721e-04 eta 0:00:04
epoch [28/50] batch [10/18] time 0.395 (0.368) data 0.359 (0.317) loss_x loss_x 0.5996 (0.5812) acc_x 87.5000 (85.0000) lr 9.3721e-04 eta 0:00:02
epoch [28/50] batch [15/18] time 0.323 (0.365) data 0.288 (0.309) loss_x loss_x 0.5620 (0.6098) acc_x 84.3750 (84.5833) lr 9.3721e-04 eta 0:00:01
epoch [28/50] batch [5/31] time 0.397 (0.364) data 0.281 (0.305) loss_u loss_u 0.9595 (0.8876) acc_u 6.2500 (14.3750) lr 9.3721e-04 eta 0:00:09
epoch [28/50] batch [10/31] time 0.306 (0.364) data 0.270 (0.309) loss_u loss_u 0.8042 (0.8944) acc_u 21.8750 (12.1875) lr 9.3721e-04 eta 0:00:07
epoch [28/50] batch [15/31] time 0.310 (0.363) data 0.273 (0.311) loss_u loss_u 0.8706 (0.8823) acc_u 15.6250 (13.3333) lr 9.3721e-04 eta 0:00:05
epoch [28/50] batch [20/31] time 0.393 (0.365) data 0.357 (0.313) loss_u loss_u 0.8823 (0.8869) acc_u 12.5000 (12.6562) lr 9.3721e-04 eta 0:00:04
epoch [28/50] batch [25/31] time 0.406 (0.367) data 0.370 (0.313) loss_u loss_u 0.9702 (0.8930) acc_u 3.1250 (11.7500) lr 9.3721e-04 eta 0:00:02
epoch [28/50] batch [30/31] time 0.397 (0.368) data 0.361 (0.316) loss_u loss_u 0.8936 (0.8891) acc_u 9.3750 (12.1875) lr 9.3721e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 440
confident_label rate tensor(0.3750, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 600
clean true:594
clean false:6
clean_rate:0.99
noisy true:566
noisy false:434
after delete: len(clean_dataset) 600
after delete: len(noisy_dataset) 1000
epoch [29/50] batch [5/18] time 0.310 (0.353) data 0.275 (0.271) loss_x loss_x 0.5122 (0.5808) acc_x 90.6250 (86.2500) lr 8.7467e-04 eta 0:00:04
epoch [29/50] batch [10/18] time 0.402 (0.367) data 0.366 (0.307) loss_x loss_x 0.7896 (0.6162) acc_x 84.3750 (85.3125) lr 8.7467e-04 eta 0:00:02
epoch [29/50] batch [15/18] time 0.389 (0.371) data 0.353 (0.314) loss_x loss_x 0.3960 (0.5858) acc_x 90.6250 (85.6250) lr 8.7467e-04 eta 0:00:01
epoch [29/50] batch [5/31] time 0.318 (0.372) data 0.282 (0.320) loss_u loss_u 0.9238 (0.8977) acc_u 6.2500 (11.8750) lr 8.7467e-04 eta 0:00:09
epoch [29/50] batch [10/31] time 0.383 (0.377) data 0.276 (0.324) loss_u loss_u 0.9341 (0.8971) acc_u 6.2500 (10.9375) lr 8.7467e-04 eta 0:00:07
epoch [29/50] batch [15/31] time 0.392 (0.374) data 0.357 (0.322) loss_u loss_u 0.9355 (0.8913) acc_u 6.2500 (12.0833) lr 8.7467e-04 eta 0:00:05
epoch [29/50] batch [20/31] time 0.389 (0.375) data 0.282 (0.319) loss_u loss_u 0.8853 (0.8901) acc_u 12.5000 (12.0312) lr 8.7467e-04 eta 0:00:04
epoch [29/50] batch [25/31] time 0.402 (0.376) data 0.366 (0.320) loss_u loss_u 0.9058 (0.8962) acc_u 9.3750 (11.3750) lr 8.7467e-04 eta 0:00:02
epoch [29/50] batch [30/31] time 0.394 (0.376) data 0.357 (0.320) loss_u loss_u 0.7964 (0.8946) acc_u 21.8750 (11.4583) lr 8.7467e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 414
confident_label rate tensor(0.3800, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 608
clean true:601
clean false:7
clean_rate:0.9884868421052632
noisy true:585
noisy false:407
after delete: len(clean_dataset) 608
after delete: len(noisy_dataset) 992
epoch [30/50] batch [5/19] time 0.319 (0.350) data 0.278 (0.313) loss_x loss_x 0.7812 (0.7139) acc_x 75.0000 (81.2500) lr 8.1262e-04 eta 0:00:04
epoch [30/50] batch [10/19] time 0.392 (0.363) data 0.357 (0.319) loss_x loss_x 0.5649 (0.6577) acc_x 81.2500 (81.2500) lr 8.1262e-04 eta 0:00:03
epoch [30/50] batch [15/19] time 0.321 (0.363) data 0.278 (0.305) loss_x loss_x 0.9062 (0.6265) acc_x 81.2500 (82.7083) lr 8.1262e-04 eta 0:00:01
epoch [30/50] batch [5/31] time 0.381 (0.372) data 0.275 (0.314) loss_u loss_u 0.9258 (0.8977) acc_u 9.3750 (11.2500) lr 8.1262e-04 eta 0:00:09
epoch [30/50] batch [10/31] time 0.398 (0.377) data 0.361 (0.323) loss_u loss_u 0.8740 (0.9106) acc_u 15.6250 (10.0000) lr 8.1262e-04 eta 0:00:07
epoch [30/50] batch [15/31] time 0.395 (0.377) data 0.276 (0.321) loss_u loss_u 0.8779 (0.9098) acc_u 12.5000 (10.0000) lr 8.1262e-04 eta 0:00:06
epoch [30/50] batch [20/31] time 0.390 (0.375) data 0.350 (0.318) loss_u loss_u 0.8735 (0.9066) acc_u 9.3750 (10.4688) lr 8.1262e-04 eta 0:00:04
epoch [30/50] batch [25/31] time 0.396 (0.376) data 0.277 (0.318) loss_u loss_u 0.8330 (0.9012) acc_u 18.7500 (11.1250) lr 8.1262e-04 eta 0:00:02
epoch [30/50] batch [30/31] time 0.398 (0.376) data 0.358 (0.321) loss_u loss_u 0.8608 (0.8985) acc_u 18.7500 (11.5625) lr 8.1262e-04 eta 0:00:00
Checkpoint saved to output/caltech101_nlprompt_16shot_seed1/prompt_learner/model.pth.tar-30
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 425
confident_label rate tensor(0.3894, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 623
clean true:616
clean false:7
clean_rate:0.9887640449438202
noisy true:559
noisy false:418
after delete: len(clean_dataset) 623
after delete: len(noisy_dataset) 977
epoch [31/50] batch [5/19] time 0.380 (0.380) data 0.279 (0.331) loss_x loss_x 0.3921 (0.6933) acc_x 87.5000 (83.1250) lr 7.5131e-04 eta 0:00:05
epoch [31/50] batch [10/19] time 0.390 (0.381) data 0.281 (0.323) loss_x loss_x 0.5015 (0.7073) acc_x 90.6250 (83.7500) lr 7.5131e-04 eta 0:00:03
epoch [31/50] batch [15/19] time 0.391 (0.375) data 0.355 (0.324) loss_x loss_x 0.5332 (0.6344) acc_x 81.2500 (84.5833) lr 7.5131e-04 eta 0:00:01
epoch [31/50] batch [5/30] time 0.400 (0.384) data 0.363 (0.336) loss_u loss_u 0.8271 (0.9021) acc_u 18.7500 (10.6250) lr 7.5131e-04 eta 0:00:09
epoch [31/50] batch [10/30] time 0.308 (0.380) data 0.272 (0.332) loss_u loss_u 0.9209 (0.9058) acc_u 9.3750 (10.3125) lr 7.5131e-04 eta 0:00:07
epoch [31/50] batch [15/30] time 0.403 (0.383) data 0.367 (0.336) loss_u loss_u 0.8857 (0.9083) acc_u 12.5000 (10.2083) lr 7.5131e-04 eta 0:00:05
epoch [31/50] batch [20/30] time 0.321 (0.383) data 0.279 (0.337) loss_u loss_u 0.9839 (0.9055) acc_u 0.0000 (10.4688) lr 7.5131e-04 eta 0:00:03
epoch [31/50] batch [25/30] time 0.391 (0.382) data 0.352 (0.336) loss_u loss_u 0.8447 (0.9021) acc_u 15.6250 (10.8750) lr 7.5131e-04 eta 0:00:01
epoch [31/50] batch [30/30] time 0.391 (0.384) data 0.272 (0.337) loss_u loss_u 0.8135 (0.9021) acc_u 18.7500 (10.7292) lr 7.5131e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 391
confident_label rate tensor(0.3969, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 635
clean true:630
clean false:5
clean_rate:0.9921259842519685
noisy true:579
noisy false:386
after delete: len(clean_dataset) 635
after delete: len(noisy_dataset) 965
epoch [32/50] batch [5/19] time 0.399 (0.358) data 0.358 (0.304) loss_x loss_x 0.8633 (0.6773) acc_x 81.2500 (84.3750) lr 6.9098e-04 eta 0:00:05
epoch [32/50] batch [10/19] time 0.396 (0.368) data 0.357 (0.321) loss_x loss_x 0.6323 (0.6589) acc_x 90.6250 (83.4375) lr 6.9098e-04 eta 0:00:03
epoch [32/50] batch [15/19] time 0.390 (0.365) data 0.272 (0.315) loss_x loss_x 0.5122 (0.6437) acc_x 84.3750 (82.9167) lr 6.9098e-04 eta 0:00:01
epoch [32/50] batch [5/30] time 0.394 (0.366) data 0.358 (0.317) loss_u loss_u 0.8374 (0.9073) acc_u 18.7500 (11.8750) lr 6.9098e-04 eta 0:00:09
epoch [32/50] batch [10/30] time 0.389 (0.368) data 0.277 (0.314) loss_u loss_u 0.8813 (0.9042) acc_u 12.5000 (11.2500) lr 6.9098e-04 eta 0:00:07
epoch [32/50] batch [15/30] time 0.403 (0.373) data 0.362 (0.318) loss_u loss_u 0.9673 (0.9167) acc_u 3.1250 (9.1667) lr 6.9098e-04 eta 0:00:05
epoch [32/50] batch [20/30] time 0.405 (0.374) data 0.366 (0.319) loss_u loss_u 0.8560 (0.9156) acc_u 15.6250 (9.5312) lr 6.9098e-04 eta 0:00:03
epoch [32/50] batch [25/30] time 0.402 (0.377) data 0.361 (0.324) loss_u loss_u 0.9038 (0.9156) acc_u 9.3750 (9.6250) lr 6.9098e-04 eta 0:00:01
epoch [32/50] batch [30/30] time 0.399 (0.377) data 0.360 (0.324) loss_u loss_u 0.9043 (0.9116) acc_u 12.5000 (10.0000) lr 6.9098e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 390
confident_label rate tensor(0.3981, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 637
clean true:634
clean false:3
clean_rate:0.9952904238618524
noisy true:576
noisy false:387
after delete: len(clean_dataset) 637
after delete: len(noisy_dataset) 963
epoch [33/50] batch [5/19] time 0.397 (0.370) data 0.358 (0.314) loss_x loss_x 0.7793 (0.7842) acc_x 78.1250 (81.2500) lr 6.3188e-04 eta 0:00:05
epoch [33/50] batch [10/19] time 0.392 (0.383) data 0.277 (0.328) loss_x loss_x 0.8018 (0.6526) acc_x 81.2500 (83.4375) lr 6.3188e-04 eta 0:00:03
epoch [33/50] batch [15/19] time 0.396 (0.383) data 0.355 (0.328) loss_x loss_x 0.6030 (0.6329) acc_x 81.2500 (83.3333) lr 6.3188e-04 eta 0:00:01
epoch [33/50] batch [5/30] time 0.324 (0.373) data 0.285 (0.318) loss_u loss_u 0.9624 (0.9018) acc_u 6.2500 (11.8750) lr 6.3188e-04 eta 0:00:09
epoch [33/50] batch [10/30] time 0.396 (0.370) data 0.355 (0.315) loss_u loss_u 0.9292 (0.8991) acc_u 6.2500 (11.8750) lr 6.3188e-04 eta 0:00:07
epoch [33/50] batch [15/30] time 0.374 (0.371) data 0.273 (0.316) loss_u loss_u 0.9731 (0.9157) acc_u 3.1250 (9.7917) lr 6.3188e-04 eta 0:00:05
epoch [33/50] batch [20/30] time 0.392 (0.370) data 0.352 (0.316) loss_u loss_u 0.9585 (0.9166) acc_u 3.1250 (9.3750) lr 6.3188e-04 eta 0:00:03
epoch [33/50] batch [25/30] time 0.395 (0.371) data 0.275 (0.315) loss_u loss_u 0.8955 (0.9113) acc_u 12.5000 (9.8750) lr 6.3188e-04 eta 0:00:01
epoch [33/50] batch [30/30] time 0.404 (0.372) data 0.364 (0.317) loss_u loss_u 0.9019 (0.9087) acc_u 9.3750 (10.0000) lr 6.3188e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 377
confident_label rate tensor(0.4019, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 643
clean true:640
clean false:3
clean_rate:0.995334370139969
noisy true:583
noisy false:374
after delete: len(clean_dataset) 643
after delete: len(noisy_dataset) 957
epoch [34/50] batch [5/20] time 0.324 (0.351) data 0.288 (0.285) loss_x loss_x 0.3875 (0.6611) acc_x 87.5000 (81.8750) lr 5.7422e-04 eta 0:00:05
epoch [34/50] batch [10/20] time 0.394 (0.366) data 0.356 (0.307) loss_x loss_x 0.4810 (0.6804) acc_x 84.3750 (81.2500) lr 5.7422e-04 eta 0:00:03
epoch [34/50] batch [15/20] time 0.396 (0.370) data 0.357 (0.318) loss_x loss_x 0.7148 (0.6794) acc_x 78.1250 (81.0417) lr 5.7422e-04 eta 0:00:01
epoch [34/50] batch [20/20] time 0.397 (0.372) data 0.358 (0.320) loss_x loss_x 1.0596 (0.6614) acc_x 65.6250 (81.2500) lr 5.7422e-04 eta 0:00:00
epoch [34/50] batch [5/29] time 0.403 (0.378) data 0.363 (0.325) loss_u loss_u 0.9043 (0.9197) acc_u 12.5000 (9.3750) lr 5.7422e-04 eta 0:00:09
epoch [34/50] batch [10/29] time 0.312 (0.375) data 0.272 (0.322) loss_u loss_u 0.9395 (0.9186) acc_u 9.3750 (10.0000) lr 5.7422e-04 eta 0:00:07
epoch [34/50] batch [15/29] time 0.395 (0.378) data 0.275 (0.325) loss_u loss_u 0.9487 (0.9248) acc_u 9.3750 (9.1667) lr 5.7422e-04 eta 0:00:05
epoch [34/50] batch [20/29] time 0.313 (0.376) data 0.273 (0.322) loss_u loss_u 0.8804 (0.9197) acc_u 12.5000 (9.6875) lr 5.7422e-04 eta 0:00:03
epoch [34/50] batch [25/29] time 0.392 (0.376) data 0.279 (0.321) loss_u loss_u 0.8574 (0.9213) acc_u 15.6250 (9.3750) lr 5.7422e-04 eta 0:00:01
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 386
confident_label rate tensor(0.3900, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 624
clean true:620
clean false:4
clean_rate:0.9935897435897436
noisy true:594
noisy false:382
after delete: len(clean_dataset) 624
after delete: len(noisy_dataset) 976
epoch [35/50] batch [5/19] time 0.403 (0.371) data 0.363 (0.331) loss_x loss_x 0.7437 (0.6436) acc_x 81.2500 (84.3750) lr 5.1825e-04 eta 0:00:05
epoch [35/50] batch [10/19] time 0.308 (0.366) data 0.269 (0.312) loss_x loss_x 0.7812 (0.6481) acc_x 78.1250 (83.4375) lr 5.1825e-04 eta 0:00:03
epoch [35/50] batch [15/19] time 0.394 (0.369) data 0.283 (0.306) loss_x loss_x 0.4414 (0.6196) acc_x 87.5000 (85.0000) lr 5.1825e-04 eta 0:00:01
epoch [35/50] batch [5/30] time 0.321 (0.365) data 0.276 (0.301) loss_u loss_u 0.8994 (0.9269) acc_u 9.3750 (9.3750) lr 5.1825e-04 eta 0:00:09
epoch [35/50] batch [10/30] time 0.403 (0.367) data 0.362 (0.307) loss_u loss_u 0.9365 (0.9304) acc_u 6.2500 (8.1250) lr 5.1825e-04 eta 0:00:07
epoch [35/50] batch [15/30] time 0.325 (0.366) data 0.286 (0.305) loss_u loss_u 0.7891 (0.9007) acc_u 25.0000 (11.2500) lr 5.1825e-04 eta 0:00:05
epoch [35/50] batch [20/30] time 0.318 (0.368) data 0.278 (0.307) loss_u loss_u 0.9614 (0.9107) acc_u 6.2500 (10.1562) lr 5.1825e-04 eta 0:00:03
epoch [35/50] batch [25/30] time 0.403 (0.374) data 0.361 (0.316) loss_u loss_u 0.9492 (0.9110) acc_u 9.3750 (10.2500) lr 5.1825e-04 eta 0:00:01
epoch [35/50] batch [30/30] time 0.304 (0.372) data 0.265 (0.313) loss_u loss_u 0.9004 (0.9119) acc_u 12.5000 (10.1042) lr 5.1825e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 382
confident_label rate tensor(0.4044, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 647
clean true:641
clean false:6
clean_rate:0.990726429675425
noisy true:577
noisy false:376
after delete: len(clean_dataset) 647
after delete: len(noisy_dataset) 953
epoch [36/50] batch [5/20] time 0.313 (0.347) data 0.274 (0.278) loss_x loss_x 0.9600 (0.8566) acc_x 75.0000 (80.6250) lr 4.6417e-04 eta 0:00:05
epoch [36/50] batch [10/20] time 0.396 (0.353) data 0.357 (0.284) loss_x loss_x 0.4766 (0.6625) acc_x 90.6250 (83.4375) lr 4.6417e-04 eta 0:00:03
epoch [36/50] batch [15/20] time 0.378 (0.361) data 0.271 (0.297) loss_x loss_x 0.8535 (0.6089) acc_x 71.8750 (83.3333) lr 4.6417e-04 eta 0:00:01
epoch [36/50] batch [20/20] time 0.392 (0.361) data 0.354 (0.300) loss_x loss_x 0.2302 (0.5600) acc_x 93.7500 (84.5312) lr 4.6417e-04 eta 0:00:00
epoch [36/50] batch [5/29] time 0.315 (0.358) data 0.275 (0.297) loss_u loss_u 0.9077 (0.8979) acc_u 9.3750 (11.2500) lr 4.6417e-04 eta 0:00:08
epoch [36/50] batch [10/29] time 0.391 (0.358) data 0.352 (0.298) loss_u loss_u 0.9180 (0.8967) acc_u 9.3750 (11.5625) lr 4.6417e-04 eta 0:00:06
epoch [36/50] batch [15/29] time 0.396 (0.358) data 0.356 (0.297) loss_u loss_u 0.8774 (0.9081) acc_u 15.6250 (10.4167) lr 4.6417e-04 eta 0:00:05
epoch [36/50] batch [20/29] time 0.310 (0.358) data 0.271 (0.299) loss_u loss_u 0.8633 (0.9090) acc_u 12.5000 (10.3125) lr 4.6417e-04 eta 0:00:03
epoch [36/50] batch [25/29] time 0.320 (0.359) data 0.280 (0.299) loss_u loss_u 0.9741 (0.9093) acc_u 3.1250 (10.3750) lr 4.6417e-04 eta 0:00:01
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 368
confident_label rate tensor(0.3987, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 638
clean true:636
clean false:2
clean_rate:0.9968652037617555
noisy true:596
noisy false:366
after delete: len(clean_dataset) 638
after delete: len(noisy_dataset) 962
epoch [37/50] batch [5/19] time 0.309 (0.346) data 0.271 (0.294) loss_x loss_x 0.5195 (0.4031) acc_x 87.5000 (86.8750) lr 4.1221e-04 eta 0:00:04
epoch [37/50] batch [10/19] time 0.395 (0.362) data 0.356 (0.308) loss_x loss_x 0.3257 (0.5007) acc_x 87.5000 (85.9375) lr 4.1221e-04 eta 0:00:03
epoch [37/50] batch [15/19] time 0.313 (0.362) data 0.274 (0.307) loss_x loss_x 1.0039 (0.5831) acc_x 78.1250 (84.3750) lr 4.1221e-04 eta 0:00:01
epoch [37/50] batch [5/30] time 0.314 (0.359) data 0.274 (0.299) loss_u loss_u 0.8477 (0.8836) acc_u 18.7500 (13.7500) lr 4.1221e-04 eta 0:00:08
epoch [37/50] batch [10/30] time 0.316 (0.360) data 0.277 (0.300) loss_u loss_u 0.9175 (0.9025) acc_u 6.2500 (11.2500) lr 4.1221e-04 eta 0:00:07
epoch [37/50] batch [15/30] time 0.384 (0.362) data 0.276 (0.301) loss_u loss_u 0.8677 (0.8973) acc_u 15.6250 (12.0833) lr 4.1221e-04 eta 0:00:05
epoch [37/50] batch [20/30] time 0.307 (0.357) data 0.271 (0.295) loss_u loss_u 0.8599 (0.9005) acc_u 15.6250 (11.5625) lr 4.1221e-04 eta 0:00:03
epoch [37/50] batch [25/30] time 0.392 (0.357) data 0.356 (0.297) loss_u loss_u 0.8979 (0.9043) acc_u 12.5000 (11.0000) lr 4.1221e-04 eta 0:00:01
epoch [37/50] batch [30/30] time 0.394 (0.357) data 0.357 (0.298) loss_u loss_u 0.9229 (0.9092) acc_u 9.3750 (10.3125) lr 4.1221e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 387
confident_label rate tensor(0.3925, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 628
clean true:626
clean false:2
clean_rate:0.9968152866242038
noisy true:587
noisy false:385
after delete: len(clean_dataset) 628
after delete: len(noisy_dataset) 972
epoch [38/50] batch [5/19] time 0.409 (0.428) data 0.373 (0.392) loss_x loss_x 0.4197 (0.5975) acc_x 93.7500 (83.7500) lr 3.6258e-04 eta 0:00:05
epoch [38/50] batch [10/19] time 0.403 (0.414) data 0.367 (0.378) loss_x loss_x 0.5957 (0.5818) acc_x 78.1250 (83.4375) lr 3.6258e-04 eta 0:00:03
epoch [38/50] batch [15/19] time 0.325 (0.409) data 0.289 (0.369) loss_x loss_x 0.3318 (0.5646) acc_x 93.7500 (85.0000) lr 3.6258e-04 eta 0:00:01
epoch [38/50] batch [5/30] time 0.312 (0.398) data 0.275 (0.352) loss_u loss_u 0.9097 (0.9064) acc_u 9.3750 (11.2500) lr 3.6258e-04 eta 0:00:09
epoch [38/50] batch [10/30] time 0.401 (0.394) data 0.365 (0.350) loss_u loss_u 0.9175 (0.9081) acc_u 9.3750 (10.9375) lr 3.6258e-04 eta 0:00:07
epoch [38/50] batch [15/30] time 0.390 (0.392) data 0.283 (0.344) loss_u loss_u 0.9048 (0.9134) acc_u 9.3750 (10.6250) lr 3.6258e-04 eta 0:00:05
epoch [38/50] batch [20/30] time 0.401 (0.388) data 0.365 (0.340) loss_u loss_u 0.8950 (0.9086) acc_u 12.5000 (10.9375) lr 3.6258e-04 eta 0:00:03
epoch [38/50] batch [25/30] time 0.328 (0.385) data 0.286 (0.335) loss_u loss_u 0.8755 (0.9049) acc_u 12.5000 (11.1250) lr 3.6258e-04 eta 0:00:01
epoch [38/50] batch [30/30] time 0.314 (0.382) data 0.278 (0.332) loss_u loss_u 0.9429 (0.9080) acc_u 6.2500 (10.7292) lr 3.6258e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 413
confident_label rate tensor(0.4006, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 641
clean true:637
clean false:4
clean_rate:0.9937597503900156
noisy true:550
noisy false:409
after delete: len(clean_dataset) 641
after delete: len(noisy_dataset) 959
epoch [39/50] batch [5/20] time 0.314 (0.373) data 0.279 (0.306) loss_x loss_x 0.5220 (0.6667) acc_x 84.3750 (82.5000) lr 3.1545e-04 eta 0:00:05
epoch [39/50] batch [10/20] time 0.318 (0.367) data 0.282 (0.307) loss_x loss_x 0.4487 (0.5743) acc_x 90.6250 (85.9375) lr 3.1545e-04 eta 0:00:03
epoch [39/50] batch [15/20] time 0.394 (0.370) data 0.358 (0.318) loss_x loss_x 0.3525 (0.5685) acc_x 84.3750 (85.4167) lr 3.1545e-04 eta 0:00:01
epoch [39/50] batch [20/20] time 0.393 (0.368) data 0.357 (0.312) loss_x loss_x 0.6382 (0.5958) acc_x 81.2500 (84.5312) lr 3.1545e-04 eta 0:00:00
epoch [39/50] batch [5/29] time 0.383 (0.366) data 0.347 (0.311) loss_u loss_u 0.9033 (0.9194) acc_u 9.3750 (9.3750) lr 3.1545e-04 eta 0:00:08
epoch [39/50] batch [10/29] time 0.399 (0.368) data 0.363 (0.314) loss_u loss_u 0.9551 (0.9202) acc_u 3.1250 (8.7500) lr 3.1545e-04 eta 0:00:07
epoch [39/50] batch [15/29] time 0.394 (0.367) data 0.358 (0.313) loss_u loss_u 0.9375 (0.9180) acc_u 9.3750 (9.3750) lr 3.1545e-04 eta 0:00:05
epoch [39/50] batch [20/29] time 0.392 (0.369) data 0.272 (0.314) loss_u loss_u 0.9624 (0.9120) acc_u 3.1250 (9.6875) lr 3.1545e-04 eta 0:00:03
epoch [39/50] batch [25/29] time 0.324 (0.368) data 0.283 (0.312) loss_u loss_u 0.9653 (0.9127) acc_u 3.1250 (9.7500) lr 3.1545e-04 eta 0:00:01
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 405
confident_label rate tensor(0.3937, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 630
clean true:628
clean false:2
clean_rate:0.9968253968253968
noisy true:567
noisy false:403
after delete: len(clean_dataset) 630
after delete: len(noisy_dataset) 970
epoch [40/50] batch [5/19] time 0.380 (0.353) data 0.269 (0.283) loss_x loss_x 0.6479 (0.6140) acc_x 84.3750 (85.0000) lr 2.7103e-04 eta 0:00:04
epoch [40/50] batch [10/19] time 0.396 (0.358) data 0.357 (0.296) loss_x loss_x 0.5083 (0.5249) acc_x 87.5000 (87.8125) lr 2.7103e-04 eta 0:00:03
epoch [40/50] batch [15/19] time 0.387 (0.359) data 0.346 (0.304) loss_x loss_x 0.7461 (0.5442) acc_x 81.2500 (87.0833) lr 2.7103e-04 eta 0:00:01
epoch [40/50] batch [5/30] time 0.394 (0.361) data 0.276 (0.302) loss_u loss_u 0.9199 (0.8987) acc_u 9.3750 (12.5000) lr 2.7103e-04 eta 0:00:09
epoch [40/50] batch [10/30] time 0.409 (0.368) data 0.368 (0.313) loss_u loss_u 0.9619 (0.9125) acc_u 3.1250 (10.9375) lr 2.7103e-04 eta 0:00:07
epoch [40/50] batch [15/30] time 0.402 (0.373) data 0.363 (0.317) loss_u loss_u 0.9424 (0.9148) acc_u 9.3750 (10.4167) lr 2.7103e-04 eta 0:00:05
epoch [40/50] batch [20/30] time 0.402 (0.374) data 0.361 (0.316) loss_u loss_u 0.9648 (0.9158) acc_u 3.1250 (10.3125) lr 2.7103e-04 eta 0:00:03
epoch [40/50] batch [25/30] time 0.402 (0.377) data 0.363 (0.321) loss_u loss_u 0.8682 (0.9129) acc_u 15.6250 (10.3750) lr 2.7103e-04 eta 0:00:01
epoch [40/50] batch [30/30] time 0.398 (0.375) data 0.357 (0.320) loss_u loss_u 0.8926 (0.9096) acc_u 12.5000 (10.9375) lr 2.7103e-04 eta 0:00:00
Checkpoint saved to output/caltech101_nlprompt_16shot_seed1/prompt_learner/model.pth.tar-40
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 410
confident_label rate tensor(0.4019, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 643
clean true:638
clean false:5
clean_rate:0.9922239502332815
noisy true:552
noisy false:405
after delete: len(clean_dataset) 643
after delete: len(noisy_dataset) 957
epoch [41/50] batch [5/20] time 0.394 (0.356) data 0.354 (0.300) loss_x loss_x 0.7231 (0.6874) acc_x 81.2500 (82.5000) lr 2.2949e-04 eta 0:00:05
epoch [41/50] batch [10/20] time 0.400 (0.367) data 0.360 (0.320) loss_x loss_x 0.6797 (0.5966) acc_x 84.3750 (84.6875) lr 2.2949e-04 eta 0:00:03
epoch [41/50] batch [15/20] time 0.315 (0.365) data 0.276 (0.311) loss_x loss_x 0.6157 (0.6532) acc_x 87.5000 (82.9167) lr 2.2949e-04 eta 0:00:01
epoch [41/50] batch [20/20] time 0.403 (0.369) data 0.364 (0.318) loss_x loss_x 0.5020 (0.6343) acc_x 81.2500 (83.5938) lr 2.2949e-04 eta 0:00:00
epoch [41/50] batch [5/29] time 0.319 (0.367) data 0.280 (0.313) loss_u loss_u 0.9404 (0.9329) acc_u 6.2500 (7.5000) lr 2.2949e-04 eta 0:00:08
epoch [41/50] batch [10/29] time 0.396 (0.369) data 0.357 (0.315) loss_u loss_u 0.9556 (0.9240) acc_u 6.2500 (8.1250) lr 2.2949e-04 eta 0:00:07
epoch [41/50] batch [15/29] time 0.384 (0.370) data 0.272 (0.316) loss_u loss_u 0.9277 (0.9105) acc_u 9.3750 (10.0000) lr 2.2949e-04 eta 0:00:05
epoch [41/50] batch [20/29] time 0.385 (0.371) data 0.275 (0.317) loss_u loss_u 0.9219 (0.9126) acc_u 6.2500 (9.6875) lr 2.2949e-04 eta 0:00:03
epoch [41/50] batch [25/29] time 0.492 (0.375) data 0.451 (0.320) loss_u loss_u 0.8682 (0.9105) acc_u 15.6250 (10.0000) lr 2.2949e-04 eta 0:00:01
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 412
confident_label rate tensor(0.3944, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 631
clean true:629
clean false:2
clean_rate:0.9968304278922345
noisy true:559
noisy false:410
after delete: len(clean_dataset) 631
after delete: len(noisy_dataset) 969
epoch [42/50] batch [5/19] time 0.311 (0.334) data 0.271 (0.264) loss_x loss_x 0.4226 (0.5924) acc_x 90.6250 (87.5000) lr 1.9098e-04 eta 0:00:04
epoch [42/50] batch [10/19] time 0.391 (0.356) data 0.352 (0.301) loss_x loss_x 0.5596 (0.5816) acc_x 87.5000 (87.1875) lr 1.9098e-04 eta 0:00:03
epoch [42/50] batch [15/19] time 0.329 (0.358) data 0.290 (0.300) loss_x loss_x 0.5181 (0.5885) acc_x 87.5000 (86.0417) lr 1.9098e-04 eta 0:00:01
epoch [42/50] batch [5/30] time 0.400 (0.365) data 0.288 (0.305) loss_u loss_u 0.9009 (0.8634) acc_u 12.5000 (16.8750) lr 1.9098e-04 eta 0:00:09
epoch [42/50] batch [10/30] time 0.304 (0.364) data 0.269 (0.306) loss_u loss_u 0.9360 (0.9005) acc_u 9.3750 (11.8750) lr 1.9098e-04 eta 0:00:07
epoch [42/50] batch [15/30] time 0.308 (0.364) data 0.272 (0.306) loss_u loss_u 0.9702 (0.9104) acc_u 3.1250 (10.4167) lr 1.9098e-04 eta 0:00:05
epoch [42/50] batch [20/30] time 0.390 (0.366) data 0.355 (0.311) loss_u loss_u 0.9204 (0.9045) acc_u 12.5000 (10.9375) lr 1.9098e-04 eta 0:00:03
epoch [42/50] batch [25/30] time 0.400 (0.365) data 0.364 (0.309) loss_u loss_u 0.9375 (0.9031) acc_u 6.2500 (10.8750) lr 1.9098e-04 eta 0:00:01
epoch [42/50] batch [30/30] time 0.401 (0.365) data 0.360 (0.307) loss_u loss_u 0.9609 (0.9039) acc_u 3.1250 (10.8333) lr 1.9098e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 417
confident_label rate tensor(0.3894, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 623
clean true:618
clean false:5
clean_rate:0.9919743178170144
noisy true:565
noisy false:412
after delete: len(clean_dataset) 623
after delete: len(noisy_dataset) 977
epoch [43/50] batch [5/19] time 0.322 (0.352) data 0.283 (0.299) loss_x loss_x 0.6235 (0.7446) acc_x 81.2500 (80.0000) lr 1.5567e-04 eta 0:00:04
epoch [43/50] batch [10/19] time 0.314 (0.366) data 0.274 (0.311) loss_x loss_x 0.4602 (0.6709) acc_x 87.5000 (82.1875) lr 1.5567e-04 eta 0:00:03
epoch [43/50] batch [15/19] time 0.314 (0.364) data 0.275 (0.305) loss_x loss_x 0.3577 (0.6557) acc_x 96.8750 (83.5417) lr 1.5567e-04 eta 0:00:01
epoch [43/50] batch [5/30] time 0.315 (0.361) data 0.275 (0.306) loss_u loss_u 0.8955 (0.9164) acc_u 9.3750 (8.1250) lr 1.5567e-04 eta 0:00:09
epoch [43/50] batch [10/30] time 0.390 (0.364) data 0.351 (0.311) loss_u loss_u 0.8481 (0.8933) acc_u 18.7500 (11.2500) lr 1.5567e-04 eta 0:00:07
epoch [43/50] batch [15/30] time 0.390 (0.363) data 0.273 (0.310) loss_u loss_u 0.9272 (0.8972) acc_u 9.3750 (11.0417) lr 1.5567e-04 eta 0:00:05
epoch [43/50] batch [20/30] time 0.399 (0.363) data 0.359 (0.311) loss_u loss_u 0.8989 (0.9011) acc_u 12.5000 (10.7812) lr 1.5567e-04 eta 0:00:03
epoch [43/50] batch [25/30] time 0.393 (0.365) data 0.273 (0.313) loss_u loss_u 0.8472 (0.9039) acc_u 15.6250 (10.5000) lr 1.5567e-04 eta 0:00:01
epoch [43/50] batch [30/30] time 0.318 (0.364) data 0.278 (0.311) loss_u loss_u 0.8477 (0.9044) acc_u 18.7500 (10.4167) lr 1.5567e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 394
confident_label rate tensor(0.3925, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 628
clean true:624
clean false:4
clean_rate:0.9936305732484076
noisy true:582
noisy false:390
after delete: len(clean_dataset) 628
after delete: len(noisy_dataset) 972
epoch [44/50] batch [5/19] time 0.393 (0.365) data 0.353 (0.309) loss_x loss_x 0.5723 (0.5476) acc_x 87.5000 (85.0000) lr 1.2369e-04 eta 0:00:05
epoch [44/50] batch [10/19] time 0.314 (0.363) data 0.274 (0.315) loss_x loss_x 0.1627 (0.5403) acc_x 96.8750 (86.5625) lr 1.2369e-04 eta 0:00:03
epoch [44/50] batch [15/19] time 0.400 (0.368) data 0.361 (0.323) loss_x loss_x 0.8237 (0.5394) acc_x 81.2500 (86.4583) lr 1.2369e-04 eta 0:00:01
epoch [44/50] batch [5/30] time 0.397 (0.372) data 0.357 (0.325) loss_u loss_u 0.9546 (0.9302) acc_u 6.2500 (7.5000) lr 1.2369e-04 eta 0:00:09
epoch [44/50] batch [10/30] time 0.488 (0.373) data 0.369 (0.322) loss_u loss_u 0.8940 (0.9125) acc_u 12.5000 (9.3750) lr 1.2369e-04 eta 0:00:07
epoch [44/50] batch [15/30] time 0.404 (0.374) data 0.364 (0.323) loss_u loss_u 0.9209 (0.9061) acc_u 9.3750 (10.2083) lr 1.2369e-04 eta 0:00:05
epoch [44/50] batch [20/30] time 0.397 (0.377) data 0.285 (0.326) loss_u loss_u 0.7925 (0.9069) acc_u 21.8750 (10.0000) lr 1.2369e-04 eta 0:00:03
epoch [44/50] batch [25/30] time 0.396 (0.378) data 0.355 (0.326) loss_u loss_u 0.7715 (0.9004) acc_u 21.8750 (10.8750) lr 1.2369e-04 eta 0:00:01
epoch [44/50] batch [30/30] time 0.328 (0.376) data 0.283 (0.324) loss_u loss_u 0.9287 (0.9009) acc_u 9.3750 (11.2500) lr 1.2369e-04 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 383
confident_label rate tensor(0.4031, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 645
clean true:641
clean false:4
clean_rate:0.993798449612403
noisy true:576
noisy false:379
after delete: len(clean_dataset) 645
after delete: len(noisy_dataset) 955
epoch [45/50] batch [5/20] time 0.310 (0.343) data 0.270 (0.303) loss_x loss_x 1.0713 (0.6870) acc_x 68.7500 (79.3750) lr 9.5173e-05 eta 0:00:05
epoch [45/50] batch [10/20] time 0.400 (0.361) data 0.361 (0.313) loss_x loss_x 0.6416 (0.6491) acc_x 71.8750 (80.9375) lr 9.5173e-05 eta 0:00:03
epoch [45/50] batch [15/20] time 0.391 (0.367) data 0.352 (0.317) loss_x loss_x 0.5327 (0.6143) acc_x 84.3750 (83.3333) lr 9.5173e-05 eta 0:00:01
epoch [45/50] batch [20/20] time 0.395 (0.365) data 0.356 (0.311) loss_x loss_x 0.4934 (0.5931) acc_x 93.7500 (83.5938) lr 9.5173e-05 eta 0:00:00
epoch [45/50] batch [5/29] time 0.391 (0.364) data 0.272 (0.304) loss_u loss_u 0.9312 (0.9166) acc_u 6.2500 (8.7500) lr 9.5173e-05 eta 0:00:08
epoch [45/50] batch [10/29] time 0.398 (0.367) data 0.357 (0.310) loss_u loss_u 0.9302 (0.9198) acc_u 9.3750 (9.0625) lr 9.5173e-05 eta 0:00:06
epoch [45/50] batch [15/29] time 0.388 (0.368) data 0.276 (0.310) loss_u loss_u 0.8784 (0.9208) acc_u 12.5000 (8.9583) lr 9.5173e-05 eta 0:00:05
epoch [45/50] batch [20/29] time 0.398 (0.368) data 0.358 (0.312) loss_u loss_u 0.8760 (0.9186) acc_u 12.5000 (9.0625) lr 9.5173e-05 eta 0:00:03
epoch [45/50] batch [25/29] time 0.405 (0.371) data 0.365 (0.317) loss_u loss_u 0.9336 (0.9161) acc_u 6.2500 (9.1250) lr 9.5173e-05 eta 0:00:01
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 407
confident_label rate tensor(0.3981, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 637
clean true:633
clean false:4
clean_rate:0.9937205651491365
noisy true:560
noisy false:403
after delete: len(clean_dataset) 637
after delete: len(noisy_dataset) 963
epoch [46/50] batch [5/19] time 0.398 (0.373) data 0.358 (0.320) loss_x loss_x 0.4680 (0.4458) acc_x 87.5000 (88.1250) lr 7.0224e-05 eta 0:00:05
epoch [46/50] batch [10/19] time 0.391 (0.376) data 0.271 (0.307) loss_x loss_x 0.5249 (0.4614) acc_x 81.2500 (86.8750) lr 7.0224e-05 eta 0:00:03
epoch [46/50] batch [15/19] time 0.397 (0.378) data 0.357 (0.314) loss_x loss_x 0.5342 (0.4922) acc_x 87.5000 (86.6667) lr 7.0224e-05 eta 0:00:01
epoch [46/50] batch [5/30] time 0.315 (0.382) data 0.275 (0.322) loss_u loss_u 0.8433 (0.9182) acc_u 15.6250 (8.7500) lr 7.0224e-05 eta 0:00:09
epoch [46/50] batch [10/30] time 0.480 (0.388) data 0.369 (0.329) loss_u loss_u 0.9092 (0.9230) acc_u 9.3750 (8.4375) lr 7.0224e-05 eta 0:00:07
epoch [46/50] batch [15/30] time 0.400 (0.387) data 0.364 (0.329) loss_u loss_u 0.8394 (0.9123) acc_u 18.7500 (9.3750) lr 7.0224e-05 eta 0:00:05
epoch [46/50] batch [20/30] time 0.336 (0.389) data 0.295 (0.332) loss_u loss_u 0.9077 (0.9146) acc_u 9.3750 (9.3750) lr 7.0224e-05 eta 0:00:03
epoch [46/50] batch [25/30] time 0.407 (0.390) data 0.367 (0.335) loss_u loss_u 0.9570 (0.9107) acc_u 6.2500 (9.8750) lr 7.0224e-05 eta 0:00:01
epoch [46/50] batch [30/30] time 0.401 (0.391) data 0.360 (0.337) loss_u loss_u 0.9463 (0.9134) acc_u 6.2500 (9.8958) lr 7.0224e-05 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 382
confident_label rate tensor(0.4038, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 646
clean true:640
clean false:6
clean_rate:0.9907120743034056
noisy true:578
noisy false:376
after delete: len(clean_dataset) 646
after delete: len(noisy_dataset) 954
epoch [47/50] batch [5/20] time 0.390 (0.367) data 0.279 (0.297) loss_x loss_x 0.6616 (0.6582) acc_x 78.1250 (81.2500) lr 4.8943e-05 eta 0:00:05
epoch [47/50] batch [10/20] time 0.394 (0.365) data 0.355 (0.303) loss_x loss_x 0.3474 (0.6551) acc_x 90.6250 (82.8125) lr 4.8943e-05 eta 0:00:03
epoch [47/50] batch [15/20] time 0.313 (0.364) data 0.273 (0.304) loss_x loss_x 0.3054 (0.6426) acc_x 93.7500 (83.3333) lr 4.8943e-05 eta 0:00:01
epoch [47/50] batch [20/20] time 0.390 (0.367) data 0.277 (0.305) loss_x loss_x 0.8032 (0.6476) acc_x 81.2500 (83.4375) lr 4.8943e-05 eta 0:00:00
epoch [47/50] batch [5/29] time 0.394 (0.366) data 0.354 (0.306) loss_u loss_u 0.8892 (0.8878) acc_u 12.5000 (11.8750) lr 4.8943e-05 eta 0:00:08
epoch [47/50] batch [10/29] time 0.310 (0.365) data 0.197 (0.301) loss_u loss_u 0.8701 (0.9083) acc_u 18.7500 (11.2500) lr 4.8943e-05 eta 0:00:06
epoch [47/50] batch [15/29] time 0.310 (0.364) data 0.273 (0.305) loss_u loss_u 0.9141 (0.9141) acc_u 9.3750 (10.6250) lr 4.8943e-05 eta 0:00:05
epoch [47/50] batch [20/29] time 0.401 (0.368) data 0.292 (0.304) loss_u loss_u 0.9043 (0.9176) acc_u 9.3750 (10.0000) lr 4.8943e-05 eta 0:00:03
epoch [47/50] batch [25/29] time 0.399 (0.372) data 0.363 (0.309) loss_u loss_u 0.9038 (0.9129) acc_u 9.3750 (10.1250) lr 4.8943e-05 eta 0:00:01
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 380
confident_label rate tensor(0.4156, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 665
clean true:660
clean false:5
clean_rate:0.9924812030075187
noisy true:560
noisy false:375
after delete: len(clean_dataset) 665
after delete: len(noisy_dataset) 935
epoch [48/50] batch [5/20] time 0.414 (0.374) data 0.367 (0.319) loss_x loss_x 0.3828 (0.5950) acc_x 93.7500 (85.0000) lr 3.1417e-05 eta 0:00:05
epoch [48/50] batch [10/20] time 0.319 (0.375) data 0.283 (0.316) loss_x loss_x 0.4714 (0.5939) acc_x 84.3750 (85.3125) lr 3.1417e-05 eta 0:00:03
epoch [48/50] batch [15/20] time 0.341 (0.377) data 0.305 (0.321) loss_x loss_x 0.8457 (0.5601) acc_x 71.8750 (85.6250) lr 3.1417e-05 eta 0:00:01
epoch [48/50] batch [20/20] time 0.390 (0.377) data 0.275 (0.319) loss_x loss_x 0.3071 (0.5612) acc_x 90.6250 (85.7812) lr 3.1417e-05 eta 0:00:00
epoch [48/50] batch [5/29] time 0.330 (0.374) data 0.289 (0.318) loss_u loss_u 0.8291 (0.9324) acc_u 18.7500 (9.3750) lr 3.1417e-05 eta 0:00:08
epoch [48/50] batch [10/29] time 0.398 (0.378) data 0.282 (0.317) loss_u loss_u 0.9541 (0.9266) acc_u 6.2500 (9.3750) lr 3.1417e-05 eta 0:00:07
epoch [48/50] batch [15/29] time 0.325 (0.376) data 0.288 (0.316) loss_u loss_u 0.9028 (0.9211) acc_u 9.3750 (9.7917) lr 3.1417e-05 eta 0:00:05
epoch [48/50] batch [20/29] time 0.313 (0.376) data 0.277 (0.318) loss_u loss_u 0.9126 (0.9257) acc_u 9.3750 (9.2188) lr 3.1417e-05 eta 0:00:03
epoch [48/50] batch [25/29] time 0.312 (0.377) data 0.276 (0.319) loss_u loss_u 0.8823 (0.9227) acc_u 12.5000 (9.3750) lr 3.1417e-05 eta 0:00:01
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 381
confident_label rate tensor(0.3962, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 634
clean true:630
clean false:4
clean_rate:0.9936908517350158
noisy true:589
noisy false:377
after delete: len(clean_dataset) 634
after delete: len(noisy_dataset) 966
epoch [49/50] batch [5/19] time 0.403 (0.357) data 0.367 (0.303) loss_x loss_x 0.6343 (0.5121) acc_x 84.3750 (86.8750) lr 1.7713e-05 eta 0:00:04
epoch [49/50] batch [10/19] time 0.396 (0.368) data 0.359 (0.323) loss_x loss_x 0.6440 (0.5303) acc_x 84.3750 (85.0000) lr 1.7713e-05 eta 0:00:03
epoch [49/50] batch [15/19] time 0.394 (0.372) data 0.359 (0.330) loss_x loss_x 0.5190 (0.5375) acc_x 81.2500 (83.7500) lr 1.7713e-05 eta 0:00:01
epoch [49/50] batch [5/30] time 0.406 (0.374) data 0.370 (0.324) loss_u loss_u 0.9458 (0.9311) acc_u 6.2500 (7.5000) lr 1.7713e-05 eta 0:00:09
epoch [49/50] batch [10/30] time 0.400 (0.379) data 0.363 (0.331) loss_u loss_u 0.8501 (0.9120) acc_u 15.6250 (9.3750) lr 1.7713e-05 eta 0:00:07
epoch [49/50] batch [15/30] time 0.413 (0.385) data 0.371 (0.336) loss_u loss_u 0.9307 (0.9127) acc_u 6.2500 (9.3750) lr 1.7713e-05 eta 0:00:05
epoch [49/50] batch [20/30] time 0.394 (0.384) data 0.357 (0.333) loss_u loss_u 0.9438 (0.9173) acc_u 6.2500 (9.2188) lr 1.7713e-05 eta 0:00:03
epoch [49/50] batch [25/30] time 0.398 (0.384) data 0.356 (0.332) loss_u loss_u 0.9482 (0.9111) acc_u 6.2500 (10.0000) lr 1.7713e-05 eta 0:00:01
epoch [49/50] batch [30/30] time 0.394 (0.385) data 0.357 (0.335) loss_u loss_u 0.8662 (0.9075) acc_u 12.5000 (10.6250) lr 1.7713e-05 eta 0:00:00
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
before epoch:data num: 1600
before epoch:different number: 392
confident_label rate tensor(0.3975, device='cuda:0')
before: len(self.train) 1600
before: len of confident samples 636
clean true:631
clean false:5
clean_rate:0.9921383647798742
noisy true:577
noisy false:387
after delete: len(clean_dataset) 636
after delete: len(noisy_dataset) 964
epoch [50/50] batch [5/19] time 0.406 (0.393) data 0.370 (0.339) loss_x loss_x 0.6255 (0.5502) acc_x 84.3750 (86.2500) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [10/19] time 0.491 (0.416) data 0.371 (0.355) loss_x loss_x 0.4180 (0.5380) acc_x 87.5000 (84.6875) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [15/19] time 0.381 (0.410) data 0.274 (0.346) loss_x loss_x 0.6689 (0.5456) acc_x 75.0000 (84.7917) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [5/30] time 0.397 (0.403) data 0.355 (0.342) loss_u loss_u 0.8618 (0.9274) acc_u 15.6250 (8.7500) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [10/30] time 0.349 (0.399) data 0.307 (0.338) loss_u loss_u 0.9326 (0.9184) acc_u 6.2500 (9.6875) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [15/30] time 0.392 (0.399) data 0.355 (0.338) loss_u loss_u 0.9111 (0.9147) acc_u 9.3750 (9.5833) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [20/30] time 0.398 (0.399) data 0.361 (0.341) loss_u loss_u 0.8726 (0.9164) acc_u 12.5000 (9.3750) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [25/30] time 0.484 (0.403) data 0.371 (0.344) loss_u loss_u 0.8628 (0.9145) acc_u 15.6250 (9.6250) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [30/30] time 0.402 (0.403) data 0.365 (0.345) loss_u loss_u 0.8896 (0.9127) acc_u 12.5000 (9.8958) lr 7.8853e-06 eta 0:00:00
Checkpoint saved to output/caltech101_nlprompt_16shot_seed1/prompt_learner/model.pth.tar-50
after epoch: len(clean dataset) 1600
after epoch: len(noisy dataset) 1600
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 2,465
* correct: 2,219
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 86.1%
Elapsed: 0:31:59
